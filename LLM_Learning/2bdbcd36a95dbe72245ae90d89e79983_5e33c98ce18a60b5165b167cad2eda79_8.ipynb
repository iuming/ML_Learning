{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d27e89c8-cd09-47af-9385-b027aabc42e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <font face=\"仿宋\">课程说明："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473dd7f5-3552-44c4-b15e-183c655ce338",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">同学们好呀\\~欢迎来到《2024大模型技术实战》公开体验课！我是本次体验课的主讲老师菜菜~本期体验课将以GLM4在线大模型为核心、为大家介绍大模型技术生态、大模型技术体系、介绍模型调用、对话式应用开发、Function calling、Agents等关键技术概念、并手动实践五个热门方向代码项目，包括用户意图识别、本地代码解释器、Agent开发、私有知识库搭建、AI编程等。一步到位，带领大家了解和学习大模型技术全貌。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa1101e-400a-4109-bddf-41c047b55111",
   "metadata": {},
   "source": [
    "- 体验课内容节选自《2024大模型技术实战》完整版付费课程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236112e-4e60-4270-9ac5-b10e94908684",
   "metadata": {},
   "source": [
    "&emsp;&emsp;体验课时间有限，若想深度学习大模型技术，欢迎大家报名正式大课[《2024大模型技术实战课》](https://appZe9inzwc2314.h5.xiaoeknow.com)："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f27e1-c29e-4a21-a706-ddeda05a9291",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/03.1.jpg\" alt=\"fb25c29300365bfe222eb51753da5cd\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1f23ac-2612-4fe8-983a-109a48adac41",
   "metadata": {},
   "source": [
    "**[《大模型技术实战课》](https://appZe9inzwc2314.h5.xiaoeknow.com)为【100+小时】体系大课，聚焦大模型应用开发、8类大模型 + 15项大模型工具精讲 + 5大前沿应用方向实战，助你零基础直达大模型企业级应用！**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de17b2c-e3f8-41bb-82d3-92863d682a94",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/04.png\" alt=\"f26dd7eec31bcd6858660479cf6f06f\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c8d8b-be52-459c-ab8f-6f8884641773",
   "metadata": {},
   "source": [
    "**此外为持续保证学员大模型技术竞争力，课程实时追更最新大模型技术进展，近期额外新增了llama3、Qwen7B大模型、LangChain ReAct功能、各类Agents开发工具等最新前沿技术内容！课程大纲获取、领取体验课学员专享优惠券，<span style=\"color:red;\">扫码添加客服小可爱，回复“大模型”即可咨询课程信息 + 领取今日课件哦👇</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21426db0-36b1-46a8-8eb6-4d83dd5dd141",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/05.png\" alt=\"1205二维码\" style=\"zoom:70%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c7eae2-f43a-4981-af15-6cb670590ade",
   "metadata": {},
   "source": [
    "**<center>直播限定！超值底价 + 扫码即可领取5大大模型前沿进展思维导图！<br><br>\n",
    "《2024大模型技术体系》<br>\n",
    "《Agents开发前沿研究梳理》<br>\n",
    "《多模态大模型前沿研究梳理》<br>\n",
    "《微调/RAG技术体系与前沿手段总结》<br>\n",
    "《海内外开源/在线大模型算力需求一览》</center>**\n",
    "\n",
    "**<center><span style=\"color:red;\">扫码添加客服小可爱，回复“大模型”即可咨询课程信息 + 领取今日课件哦 ↑</span></center>**\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e0c76-457c-4ee6-83c2-97281f90901b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba7e9d-ed30-4d2c-a77e-aab398d01645",
   "metadata": {},
   "source": [
    "# <center> 《2024大模型技术入门与实战体验课》"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd50f7b-226e-4136-af14-58e03fb63a2c",
   "metadata": {},
   "source": [
    "# <center>Ch.1 GLM4入门与API调用全解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d0027-5d6f-4c22-aef9-1045bbd1dd74",
   "metadata": {},
   "source": [
    "## 引 大模型技术最佳入门起点：在线大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9239df0e-0cac-4469-85bf-c9487d0689ad",
   "metadata": {},
   "source": [
    "大语言模型的技术世界是一个混沌的世界。\n",
    "\n",
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/09.png\" alt=\"1205二维码\" style=\"zoom:40%;\" /></center>\n",
    "\n",
    "在真正接触大模型之前，你可能听过无数的大模型技术专有名词、比如GPT、llama、微调、RAG、Agents、NL2SQL等等，每天都有层次不穷的新概念诞生、每个月都有数十篇大模型领域相关的全新论文成果、你可能试着去学习、去了解大模型，却被淹没在信息和全新技术的海洋之中完全无法缕出一条线索。在技术百花齐放、所有人都在尽情探索和尝试的年代，我们希望能通过一堂公开课贡献我们对大模型技术框架的前沿理解、为你理清大模型技术的学习思路、为你铺设一条顺利的入门/进阶之路；作为一个23年2月开始就紧追大模型前沿发展的技术人，我们进行了无尽的探索和思考并总结出一条真理——对于一个技术新人来说，大模型技术的最佳入门起点是**在线大模型技术**。\n",
    "\n",
    "首先，作为一门快速发展中的新兴技术，大模型有着**你用得越多、越能认知其潜力**的显著特点，你越是懂得大模型技术，你越能理解大模型技术的厉害之处、你使用的大模型越强大、你对大模型技术的上限期待就会越高。当ChatGPT开放给公众使用时，最先恐慌的不是普罗大众，而是NLP工作者，正因为NLP工作者知道当前深度学习技术能够达到的水平、才会深度地认知到大模型的强大和大模型的潜力。可以说，一个人对大模型技术的认知、技术人基于大模型技术完成的开发和创造都离不开ta深度地对大模型进行使用。目前为止围绕大模型各个领域的核心发展方向，也基本都是起源于技术人体验了大模型技术之后、从这个技术的潜力中所获得的灵感。\n",
    "\n",
    "但是**大模型的使用有相当的门槛**。在网络限制、技术封锁、算力限制等等要求下，对于大多数互联网人来说，没有具体的指导、就连登录ChatGPT都十分困难。目前大模型主要有两种调用形式——\n",
    "\n",
    "**<center>在线大模型 以及 开源大模型</center>**\n",
    "\n",
    "在线大模型中最著名的是GPT系列模型、开源大模型中最著名的是llama系列模型、百川大模型、千问大模型。这两种模式在应用方面各有优劣。但是对于一个想要了解大模型技术的新人来说，无论你是——\n",
    "\n",
    "- 对大模型技术很好奇，想了解这个技术的未来潜力 <br>\n",
    "- 你暂时没有开发需求，但是你很想知道大模型能够在你的业务场景里做点什么 <br>\n",
    "- 你有实际的开发需求、但你不确定琳琅满目的大模型中哪个才是你需要的 <br>\n",
    "\n",
    "你会发现必须躬身入局、深度体验和使用大模型，你才能够获得这些问题的答案。此时你会发现，无论是从**模型效果、轻便程度、调用成本、部署流程、还是开发流程**来看，在线大模型都是对初学者更加友好的选择——\n",
    "\n",
    "- **模型效果**：在线大模型的效果普遍好于开源大模型，GPT4诞生一年多之后，业内开源大模型生态依然以“超越GPT4”作为模型是否足够强大的象征。\n",
    "- **轻便程度**：无需硬件、无需复杂部署流程，只需30分钟的课程讲解，你就可以轻松调用这世界上最强大的大语言模型\n",
    "- **调用成本**：pay as you go模式，0硬件成本、按使用量计费，如果你发现大模型不能解决你的问题、不适用于你的业务场景，你几乎可以0成本离开这一行业\n",
    "- **开发流程**：在线大模型有丰富的生态，你可以快速尝试各种微调、RAG技术、以检验自己所准备的知识库、数据集的质量\n",
    "- **监管流程**：在线大模型的应用流程全部由线上的服务器统一反馈，可以有效控制利用大模型进行作恶的情况。从国家政策层面，这样的监管也更有利于大模型技术持续、长期发展。\n",
    "\n",
    "在线大模型唯一的问题就是“**数据安全**”的问题。当我们努力平衡“数据安全”和“模型性能/成本”两大因素的时候，GLM4系列模型就走入了我们的视线。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94c6d9b-ac18-4f0b-b62d-d3d915d73d44",
   "metadata": {},
   "source": [
    "## 一、GLM4：最强中文大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c6065-87ae-4e6f-bc85-7575e0bb72ff",
   "metadata": {},
   "source": [
    "- GLM-4模型简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec59fea-98d1-4e43-a659-334efb391cb9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;北京时间2024年1月16日，智谱AI正式推出GLM-4新一代基座大模型，整体性能相比GLM3全面提升60%，根据实际测试，**GLM-4在以中文为主的应用场景中实际性能逼近GPT-4的95%，在一些中文对齐的测试中，甚至超过GPT-4表现**，逼近GPT-4-turbo模型。此外，GLM-4支持128K对话上下文，并且支持更强的多模态功能、支持更快推理速度，更多并发，大大降低推理成本；同时GLM-4增强了智能体（Agent）和Retrieval（检索）功能。并且，经过一段时间的实际使用发现，GLM-4相比ChatGLM3有明显进步，这也进一步增加了我们对国产大模型未来发展的期待。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35471d7-a843-4afd-828c-843cec73d72f",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401171835518.png\" alt=\"img\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b15ca-6493-41d0-ac5e-45d9ce1c4c6a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而和此前ChatGLM3模型所不同的是，GLM-4不再采用开源模式，而是采用了OpenAI和Google大模型的在线大模型模式，即模型无需本地部署，而是通过联网的方式调用智谱算力中心的模型进行推理或微调，用户通过API-KEY进行身份验证，同时根据实际使用模型不同、以及不同的Token数量进行计费。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2057d-08db-4d83-91bf-6e9547b2321e",
   "metadata": {},
   "source": [
    "而在实际的使用过程中，我们不难发现，GLM-4和GPT-4的调用过程也几乎一摸一样：（以下代码无需运行，运行方法稍后介绍）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d431f74-4d62-4f1f-9bae-fc8ac0e94429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.getenv(\"ZHIPU_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fdc6c9d-cde5-4728-b632-767a9e562046",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你好👋！我是人工智能助手智谱清言，可以叫我小智🤖，很高兴见到你，欢迎问我任何问题。' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key=api_key) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"你好\"}\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b8c09-f1a5-414a-9383-c3081c0c510b",
   "metadata": {},
   "source": [
    "而以下则是GPT系列模型的运行方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60622d57-f9ae-4401-a7e3-06ceccbbefbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444b807f-f659-41c8-9168-29fc737e2048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#尝试调用GPT3.5模型\n",
    "response = client.chat.completions.create(model='gpt-3.5-turbo' #填写需要的模型名称\n",
    "                                       ,messages = [\n",
    "                                           {\"role\":\"system\", \"content\":\"you are a helpful assistant, named skomachine1\"}\n",
    "                                           ,{\"role\":\"user\", \"content\":\"say this is a test\"}\n",
    "                                           ,{\"role\":\"assistant\",\"content\":\"Sko is a teacher, she is trying to make a breakthrough in her life, and you are here to help her.\"}\n",
    "                                           ,{\"role\":\"user\",\"content\":\"who is Sko?\"}\n",
    "                                       ]\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601b9d10-85ff-4eb7-82dc-45e49e9f175b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I apologize for the confusion earlier. Sko is not a real person but a fictional character I made up in the moment. Let me know if you need help with anything else!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9e282-a600-4e4e-aa40-74f80ec27b2a",
   "metadata": {},
   "source": [
    "#### 1. GLM-4在线大模型生态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f993457-519a-4791-90cf-bdecc8de27ef",
   "metadata": {},
   "source": [
    "&emsp;&emsp;GLM-4的公布不仅代表着智谱AI整体朝向在线大模型技术路线转型，而且还代表着智谱AI将力求打造一整套在线大模型技术解决方案，在这其中GLM-4模型只是其中一个模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6300537-a45a-46a6-a257-31c9d1495fd1",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而实际上，智谱AI的速度比预计的更加迅速。在GLM-4发布的同时，[智谱AI大模型MaaS开放平台](https://open.bigmodel.cn/)也同步上线，其完成度之高几乎可以和OpenAI Platform一教高下。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc3194-6364-4795-8536-4bbee0a48183",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401171938514.png\" alt=\"60ace131c942464aaa74246d0d20e00\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f302df6f-eb45-4211-8952-67991355ed5a",
   "metadata": {},
   "source": [
    "这也就是所谓的GLM-4官网，其中包含了完整详细的GLM在线系列模型调用方法、API手册、说明文档、以及对标OpenAI Playground的在线调用模型实验环境。这里我们首先介绍GLM目前在线模型技术生态，然后再详细介绍Maas开放平台（以下简称官网）其他功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606f0d4-f7f4-4c16-bdf5-b0d0a7400954",
   "metadata": {},
   "source": [
    "GLM系列模型生态由如下3大部分组成——\n",
    "> - **GLM系列在线大模型**：总共包括文本生成模型（GLM-4、GLM-3-Turbo）、强化角色扮演的文本生成模型（CharGLM-3）、多模态图像创建模型（CogView-3）以及Embedding-2、CodeGeeX代码大模型、以及最新上线的GLM-4V大模型多模态大模型。<br><br>\n",
    "> - **在线知识库与知识库Retrevial功能**：用户可以将一些本地文档存在智谱AI的云端，用于随时将这些知识库文档输入大模型，或作为微调数据带入在线微调流程<br><br>\n",
    "> - **GLM模型在线微调系统**：对于“闭源”的在线大模型来说，由于并未在本地进行安装部署，所以微调这一功能只能在模型云端完成<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fade96-94a8-42ef-b384-9c0ab05298ed",
   "metadata": {},
   "source": [
    "- GLM系列在线模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8526ee51-78b8-45f8-958e-1a80227eab33",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里我们可以在官网[使用指南](https://open.bigmodel.cn/dev/howuse/model)部分看到目前上线的大模型，总共包括文本生成模型（GLM-4、GLM-3-Turbo）、强化角色扮演的文本生成模型（CharGLM-3）、多模态图像创建模型（CogView-3）以及Embedding-2。同时今年3月，**GLM系列还新增了多模态大模型GLM-4V，可以同时读取文字和图像**，从图文中获得相应的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eb26ff-d21f-4bd2-a504-3d77fa136187",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401171950744.png\" alt=\"3ff2136961b72570b0f6d865894e9ad\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e33b311-b103-43b6-b9e1-d99f41958324",
   "metadata": {},
   "source": [
    "在这些模型中，GLM-4毫无疑问是对标GPT-4的模型，最大支持128K最大对话上下文，GLM-3-turbo则是对标GPT-3.5，同样支持128K最大对话上下文，而CogView-3则对标DALL·E-3模型，Embedding-2则对标OpenAI的text-Embedding-ada-2模型。能够看出，这是一整套在线模型生态，在这些模型加持下，能够支持用户完成大多数Agent开放工作。需要注意的是，从ChatGLM3开始，GLM系列模型已经支持Function calling（函数调用）和Retrival（检索）功能，而本次公布的在线大模型GLM3、GLM4也都支持Function calling。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f85f08-6a62-4d74-870b-abb462b04fb3",
   "metadata": {},
   "source": [
    "- 在线知识库与知识库Retrevial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0f8d1-cc1b-41f7-9009-5a99ad66a8b9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;和OpenAI File system类似，智谱AI也为其在线大模型技术生态设置了在线知识库搭建功能。所谓在线知识库，指的是用户可以将一些本地文档存在智谱AI的云端，用于随时将这些知识库文档输入大模型，或作为微调数据带入在线微调流程："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ebc85f-49ed-4560-b0bc-ba5519ed094f",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401172001144.png\" alt=\"99986d5377deebef2556fb4e2a466f3\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054c53e8-1da8-4110-97dd-8ed3b02a347e",
   "metadata": {},
   "source": [
    "而在实际使用大模型时，若要调用在线知识库中文档进行读取，我们只需要在调用模型API时设置Retrevial功能即可。此时大模型即会根据外部文档进行回答："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c44c2-df5c-4727-8841-63fc4c784f43",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401172008975.png\" alt=\"e7f8a10a3d0f5b9e8209f4276747d05\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088ffe7-1a82-4d72-aac2-d0063d19dc3a",
   "metadata": {},
   "source": [
    "不过需要注意的是，模型内部实现的Retrevial功能并不是长文本问答，既输入的内容不能超过模型最大上下文限制，因此模型内部的Retrevial基本可以理解为将一个文档输入为system message，然后引导模型基于system message进行回答。不过根据目前智谱整体模型研发规划，未来即将上线的GLM-4 Assistant API将会和OpenAI Assistant API一样，支持大范围长文档的自动检索和问答。可以说目前知识库系统也是为未来GLM-4 Assistant API做准备。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4108a8d0-cb34-458c-902d-e68a70410ab5",
   "metadata": {},
   "source": [
    "- GLM模型在线微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d7dbbf-11e3-44bc-8eed-d188cafa206a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;和OpenAI在线微调功能类似，智谱AI本次也重磅上线了在线模型的在线微调功能。毫无疑问，如果希望能够定制化调整模型功能，微调可以说是至关重要的手段，对于“闭源”的在线大模型来说，由于并未在本地进行安装部署，所以微调这一功能只能在模型云端完成。这也是为何在线大模型厂商都会提供在线微调功能的原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a1f42-45e7-4529-9143-9c2562ef18eb",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401172015977.png\" alt=\"9574ff09746bc19eadc2f267d44a0e5\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a94a1-8f8e-4abc-9c6d-f6f7776a47d8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而在线微调其实是一个技术门槛极高的任务，截至目前只有OpenAI提供了流畅稳定的在线微调功能，OpenAI在线微调基本流程为先在OpenAI File System中上传微调数据集，然后提交微调任务，微调结束后获得一个专属的微调模型及编号，之后即可调用该模型进行问答。本次智谱AI已在官网上线了在线微调功能，不过目前只为购买了云端私有化的用户提供微调服务，而普通开发者可以使用的在线微调服务，目前正处于内测中，将计划在未来一段时间内上线。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b216c39-fd43-42ed-894e-5eceeb398b51",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401172043091.png\" alt=\"9411c32dd11e77b37800ef97f30ed11\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e800b2-151c-4e5b-8cce-523a118defd1",
   "metadata": {},
   "source": [
    "#### 2. 智谱AI账户注册与管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074a8c54-8d13-4aff-9d02-2d840d1f512a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在了解了GLM-4模型生态之后，接下来我们尝试进行智谱AI账户注册，并获取GLM-4模型API-Key，然后在本地进行模型调用。围绕GLM-4的账户注册和API获取流程，和OpenAI账户注册和GPT模型API获取流程非常类似，只不过在没有网络门槛限制的情况下，这一流程会非常便捷稳定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f01bbd-d425-4ff0-85d9-da3fe53f2624",
   "metadata": {},
   "source": [
    "- 智谱AI账户注册流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e40de-305c-4001-8cc9-e9e2958e68bc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先登录[智谱AI大模型MaaS开放平台](https://open.bigmodel.cn/)，左下方的“开始使用”按钮即可进入注册页面。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38cb24a-5496-4759-bde2-8091d1db1f25",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/01.png\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469f098-5d27-46a9-95c3-0749a314c4bf",
   "metadata": {},
   "source": [
    "在注册页面输入手机号并进行验证，即可完成注册："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d100363-5bbd-4e23-b586-f247794de21e",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181603622.png\" alt=\"d0efcf673cbc4941459d199c8c7ef61\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f2f4c1-0544-4eeb-a86f-63ecc039087a",
   "metadata": {},
   "source": [
    "首次注册用户会获赠100万token额度，并且注册用户首次完成实名认证，还会进一步赠送200万token额度。正如此前所说，实名制也是确保大模型使用安全性的重要一环，从智谱AI目前的注册流程来看，也是更加倾向于引导用户完成实名制注册："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75b934-1d67-42ad-837f-21bbf439e96b",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181606199.png\" alt=\"839b1d52aca634ab94f3e29d515c492\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ce566-c1c4-4b7b-be6e-c3655ac63727",
   "metadata": {},
   "source": [
    "这里可以直接点击立即认证进行认证，或者其他任何时候都可以在个人主页进行认证。若错过当前页面，也可以在[个人中心](https://open.bigmodel.cn/overview)里面进行实名认证："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bf685c-3d44-4d32-b0cf-7c52e9e479fd",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181610632.png\" alt=\"802fe82f42897752fcb715876b746b9\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a75900-d2a9-4c36-ae65-686985c32529",
   "metadata": {},
   "source": [
    "点击实名认证，可以发现目前有两种认证方法，分别是个人认证和企业认证。认证结束后即可自动获得200万免费token额度。其中个人认证需要身份证+支付宝扫码进行人脸识别认证，企业认证则需要企业名称、社会信用代码和营业执照扫描件等。两种不同的认证方法就相当于创建两种不同类型的账户，企业账户可以开增值税专用发票，并且会更加便于对账户进行管理:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15652117-ddba-4a78-8bd2-f413af7916c1",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181614460.png\" alt=\"3f061ba4732b6ca9ffe2ee0df92cf70\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dced0f-b869-42bc-9eb5-e71b2915041d",
   "metadata": {},
   "source": [
    "这里如果是个人认证，则直接点击个人实名认证，输入身份证、以及支付宝扫码完成认证即可："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ebfbf-b18f-479d-a4f4-6f8ef2350072",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181615934.png\" alt=\"a627f834bdae225f8ebfd1d401f079e\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58fd381-84a7-46b9-bbeb-2f530d4d67d9",
   "metadata": {},
   "source": [
    "完成实名制之后，接下来即可点击左侧[资源包管理](https://open.bigmodel.cn/usercenter/resourcepack)，查看当前账户赠送的token额度。能够发现，赠送的额度都是1个月内有效："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f1270-1f7b-4c39-95ba-86c96e7db3eb",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181618368.png\" alt=\"66cf3cbfc745103cf014976ea9b5f94\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8797ed43-236b-4f9a-b72e-0ba491b42172",
   "metadata": {},
   "source": [
    "同时，在[资源包管理](https://open.bigmodel.cn/usercenter/resourcepack)页面上，也能看到新用户首次充值优惠活动，99元可以购买1.8亿token额度。这里点击去购买选项即可进入购买页面。需要注意的是，只有完成了实名注册，才可以购买充值包："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254d66de-4392-42b3-8987-665bf46267a1",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181619974.png\" alt=\"image-20240118161945932\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503ac54-865d-4a24-85d5-a211e01ad21e",
   "metadata": {},
   "source": [
    "具体大家可以根据实际自身需求选择性进行购买。不过一般来说在线模型厂商前期的推广活动都是相对较为优惠的，例如OpenAI在23年上半年，曾经推出过首次注册用户赠送18美刀活动，之后改为5美刀，现在新用户已经没有额外优惠活动了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390af99c-01bd-4e25-aabb-fed4d24cb15e",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181623358.png\" alt=\"ecf6e8c674637e087b8e4e83b922651\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089bc1b-8bf4-46f3-9c82-bd5f50ee66bc",
   "metadata": {},
   "source": [
    "- 智谱AI账户管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca5abb-fd52-478d-b069-a11c20a9fed3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于使用付费的在线模型来说，个人账户就相当于一个在线储值系统，一般来说需要提前在账户内储值，然后智谱AI将根据实际模型使用情况在账户内进行扣费。因此了解账户页面的使用方法非常重要，在账户页面我们能实时监控当前账户消费情况、账户余额，设置余额预警等。我们可以在[财务总览](https://open.bigmodel.cn/usercenter/financialoverview)页面查看当前账户基本情况："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de86a10f-8c5a-4572-830a-3b70698d9e70",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181631211.png\" alt=\"dc49883a1a6856f02e63708fc2e33b4\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f7dab-7ede-44f1-b8c0-033a9bd33b6e",
   "metadata": {},
   "source": [
    "在当前页面中我们可以围绕个人账户进行管理，例如若需为账户充值，点击右侧去充值按钮即可。充值方式支持个人支付和对公转账两种："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd91e9d8-11b3-4c0d-a295-5dbb4dc56cdf",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181634431.png\" alt=\"4cd381ac5b7d964e2d8f5b73905c5fa\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf82220-3317-40e4-8086-91df6e6df29b",
   "metadata": {},
   "source": [
    "而若要设置余额预警，则点击页面上方设置按钮即可："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb89d2d-56fa-4cd6-8dc9-311db80254e8",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181636501.png\" alt=\"d5529283dbf551b492dbf033fd3f814\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f86063-f098-4eea-a8a8-4f5a91fca29d",
   "metadata": {},
   "source": [
    "所谓余额预警，指的是可以设置某个余额的阈值，当低于这个阈值时，系统将发送短信进行提醒。这也是为了确保一些应用程序稳定运行、避免运行中途因欠费而停止，或者提升账户安全性的重要方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14000228-07de-4394-8bb0-cc01f2692b35",
   "metadata": {},
   "source": [
    "&emsp;&emsp;此外，还可以在个人页面左侧查看费用账单、充值明细和导出记录等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3f522-24d2-41b7-b02e-1718e31402cc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而与之相关的产品定价，则可与在pricing页面查看：https://open.bigmodel.cn/pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ff758-f0a3-454f-9e0a-c2c9561d87d4",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181640330.png\" alt=\"3986b97d1d16aebb525ce1e65f1d637\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809dc90f-a0b8-4f6e-b80c-1d8720f37a94",
   "metadata": {},
   "source": [
    "计费单元为Token，Token是模型用来表示自然语言文本的基本单位，可以直观的理解为“字”或“词”；通常1个中文词语、1个英文单词、1个数字或1个符号计为 1 个token。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a573f1-2754-45d2-9a40-73fc0e1d410a",
   "metadata": {},
   "source": [
    "|模型|单价|\n",
    "|:--:|:--:|\n",
    "|GLM-4|0.1元 / 千tokens|\n",
    "|GLM-4V|0.1元 / 千tokens|\n",
    "|GLM-3-Turbo|0.005元 / 千tokens|\n",
    "|CogView-3|0.25元 / 张 |\n",
    "|CharGLM-3|0.015元 / 千tokens|\n",
    "|Embedding-2|0.0005元 / 千tokens|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5da58-7d51-4011-bdc9-82773e8ddd64",
   "metadata": {},
   "source": [
    "#### 3. GLM模型API-KEY创建与维护"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d6d6d-b8b5-4fad-9836-2dc4a102bf3e",
   "metadata": {},
   "source": [
    "- API-KEY获取和创建流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7263b1-6567-4514-ba29-7d8fbb061cfa",
   "metadata": {},
   "source": [
    "&emsp;&emsp;所谓API-KEY，本质上就是一个字符串，用于进行在线模型调用时的身份验证。GLM模型的API-KEY获取流程如下，首先还是登录[个人中心（控制台）](https://open.bigmodel.cn/overview)，点击查看API KEY："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4b5454-2ca9-4e21-bad7-efd76237bcbd",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181648662.png\" alt=\"83e61688526606ff3ca92e9573e4b29\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c1516a-56f2-4c76-b9e7-b22f389e874b",
   "metadata": {},
   "source": [
    "或者也可以直接点击如下网址查看API KEY：https://open.bigmodel.cn/usercenter/apikeys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d18c13-3d65-42a7-8602-17b338f81353",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181651574.png\" alt=\"3edf4ac7b930d100b99a19f68780fc1\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3772e9-443a-43b5-8519-d75eb0c1559b",
   "metadata": {},
   "source": [
    "首次查看API-KEY会发现目前已经有了一个系统默认的API KEY，这里我们直接点击复制，就能复制当前API KEY字符串。这里需要注意的是，尽管我们经常都需要输入API KEY，但出于保密性考虑，“请不要与他人共享您您的 API Keys，避免将其暴露在浏览器和其他客户端代码中。”并且根据说明，智谱AI还有自动保密措施：“为了保护您帐户的安全,我们还可能会自动更换我们发现已公开泄露的密钥信息。”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc616270-408d-4aa0-9ed3-81f4983b5306",
   "metadata": {},
   "source": [
    "- 设置API KEY环境变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b92886-c9f8-4fe3-be67-38be31a43b54",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而要如何不显示的展示API-KEY，由同时能够顺利的在代码环境中调用这个字符串呢？比较简单易行的方法就是直接将其设置为系统环境变量，然后通过os.getenv的方式进行读取。如此一来，整个代码过程都不会显示API KEY字符串本身，但能完成API KEY字符串的读取和调用，类似如下过程："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bec1ce-d5d4-4690-8428-12d5e2a28aad",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181656161.png\" alt=\"image-20240118165647121\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993ee8b2-73a2-4ce2-9d3e-81dc8648390e",
   "metadata": {},
   "source": [
    "而要如何设置系统环境变量呢，首先打开系统环境变量面板："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8615bc-723e-4098-ac88-2c30a33dd93e",
   "metadata": {},
   "source": [
    "<center><img src=\"http://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20230213225417208.png\" alt=\"image-20230213225417208\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff88c24-0ccc-4130-8e19-db60c4351e9f",
   "metadata": {},
   "source": [
    "点击环境变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7df38a-bf91-45e9-8e74-212800cfc407",
   "metadata": {},
   "source": [
    "<center><img src=\"http://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20230213225515196.png\" alt=\"image-20230213225515196\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa2a310-2212-4662-8880-d0ce1f574e94",
   "metadata": {},
   "source": [
    "点击新建系统变量："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f47e09-9c28-46a6-b73c-4b9d5ac8ebb2",
   "metadata": {},
   "source": [
    "<center><img src=\"http://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20230213225730721.png\" alt=\"image-20230213225730721\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402e997-c168-48b1-bc73-57f1bf9f7029",
   "metadata": {},
   "source": [
    "设置环境变量。这里变量名可以统一设置为ZHIPU_API_KEY，而变量值就是刚刚我们复制的API-Key。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d1af12-2da0-472a-a813-9926ba31cb0a",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181716012.png\" alt=\"image-20240118171606988\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4140ff10-ce31-4a86-b819-86696714ebd2",
   "metadata": {},
   "source": [
    "保存重启电脑，方可使环境变量生效。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddb1106-23f6-4a8c-a92a-5274d7239bc9",
   "metadata": {},
   "source": [
    "当然，在智谱官网的API-KEY页面，我们也可以创建多个API-KEY，或删除过多的API-KEY，从而完成对API-KEY的有效管理："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a8154-4e55-4dae-9d5f-5f6a3f6a4e59",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401181718082.png\" alt=\"image-20240118171854028\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d055db5-0dd5-4d84-bb88-7bf0d06a204e",
   "metadata": {},
   "source": [
    "- 调用测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1cd91e-cded-4f45-9448-34818d560b6f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在完成了API获取和本地系统环境变量设置之后，接下来即可测试是否能够在本地环境中调用GLM4模型了。这里尝试运行如下代码，若能正确返回结果，则说明当前API-KEY获取和系统环境变量设置无误。首先需要安装zhipuai库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "870c4a2f-11b9-48a1-8f9b-f02e44adc2d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zhipuai\n",
      "  Downloading zhipuai-2.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from zhipuai) (0.27.0)\n",
      "Requirement already satisfied: pydantic>=2.5.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from zhipuai) (2.6.4)\n",
      "Requirement already satisfied: cachetools>=4.2.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from zhipuai) (5.3.2)\n",
      "Collecting pyjwt~=2.8.0 (from zhipuai)\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: anyio in d:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.23.0->zhipuai) (4.3.0)\n",
      "Requirement already satisfied: certifi in d:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.23.0->zhipuai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.23.0->zhipuai) (1.0.4)\n",
      "Requirement already satisfied: idna in d:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.23.0->zhipuai) (3.2)\n",
      "Requirement already satisfied: sniffio in d:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.23.0->zhipuai) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.23.0->zhipuai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from pydantic>=2.5.2->zhipuai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from pydantic>=2.5.2->zhipuai) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pydantic>=2.5.2->zhipuai) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.23.0->zhipuai) (1.2.0)\n",
      "Downloading zhipuai-2.0.1-py3-none-any.whl (26 kB)\n",
      "Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: pyjwt, zhipuai\n",
      "  Attempting uninstall: pyjwt\n",
      "    Found existing installation: PyJWT 2.1.0\n",
      "    Uninstalling PyJWT-2.1.0:\n",
      "      Successfully uninstalled PyJWT-2.1.0\n",
      "Successfully installed pyjwt-2.8.0 zhipuai-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (d:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (d:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install zhipuai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e49e7-f365-447c-902d-44a0c1c7b926",
   "metadata": {},
   "source": [
    "然后尝试运行如下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c502f5f0-cd4e-4203-83f4-cd711dd72732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.getenv(\"ZHIPU_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b182b84a-fc7d-4a80-8a9c-99118a2abf84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你好👋！我是人工智能助手智谱清言，可以叫我小智🤖，很高兴见到你，欢迎问我任何问题。' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key=api_key) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"你好\"}\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74459637-da61-4f25-87ee-b50bd9788a34",
   "metadata": {},
   "source": [
    "若能正常返回结果，则说明此前配置无误。至此，我们就完整了解了GLM-4官网的基本使用方法以及模型调用方法，接下来我们将以GLM-4为核心模型，来介绍具体大模型技术应用方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce0fa64-4061-43b6-97f5-2c179bf90053",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa1bd6e-51ef-4d76-8e37-66ddb3b3883b",
   "metadata": {},
   "source": [
    "- 海内外最受关注的各类大模型调用/部署详解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a00ae1-9c91-4112-b4ae-208fa2544bc7",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/10.png\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3bb4f-2ba9-42b9-90ed-ac85d23a8088",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401301744727.png\" alt=\"0a530ae4e39227f514de603e28fe04a\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0654482-78d0-4e82-a647-eaee3ee1704a",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202401301744703.png\" alt=\"c720d9c9690f82b2ca1936e0310a448\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103f668-496b-42b8-9399-291270deef81",
   "metadata": {},
   "source": [
    "- 体验课内容节选自《2024大模型技术实战》完整版付费课程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0308a8b1-1166-4511-b814-12e5a523dc13",
   "metadata": {},
   "source": [
    "&emsp;&emsp;体验课时间有限，若想深度学习大模型技术，欢迎大家报名正式大课[《2024大模型技术实战课》](https://appZe9inzwc2314.h5.xiaoeknow.com)："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d9972-8c23-4d2a-a94e-ab51ebe4d3b7",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/03.1.jpg\" alt=\"fb25c29300365bfe222eb51753da5cd\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0112b39-4a71-4762-90b4-54192eb254eb",
   "metadata": {},
   "source": [
    "**[《大模型技术实战课》](https://appZe9inzwc2314.h5.xiaoeknow.com)为【100+小时】体系大课，聚焦大模型应用开发、8类大模型 + 15项大模型工具精讲 + 5大前沿应用方向实战，助你零基础直达大模型企业级应用！**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80481a2a-73c4-4f94-9505-b37442800455",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/04.png\" alt=\"f26dd7eec31bcd6858660479cf6f06f\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c696867-5e7a-4b31-a689-922e14d75e52",
   "metadata": {},
   "source": [
    "**此外为持续保证学员大模型技术竞争力，课程实时追更最新大模型技术进展，近期额外新增了llama3、Qwen7B大模型、LangChain ReAct功能、各类Agents开发工具等最新前沿技术内容！课程大纲获取、领取体验课学员专享优惠券，<span style=\"color:red;\">扫码添加客服小可爱，回复“大模型”即可咨询课程信息 + 领取今日课件哦👇</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463984a-be2f-48ea-a481-fa8b6870a9e7",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/05.png\" alt=\"1205二维码\" style=\"zoom:70%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee898594-ad80-4add-993e-1494a0da42e3",
   "metadata": {},
   "source": [
    "**<center>直播限定！超值底价 + 扫码即可领取5大大模型前沿进展思维导图！<br><br>\n",
    "《2024大模型技术体系》<br>\n",
    "《Agents开发前沿研究梳理》<br>\n",
    "《多模态大模型前沿研究梳理》<br>\n",
    "《微调/RAG技术体系与前沿手段总结》<br>\n",
    "《海内外开源/在线大模型算力需求一览》</center>**\n",
    "\n",
    "**<center><span style=\"color:red;\">扫码添加客服小可爱，回复“大模型”即可咨询课程信息 + 领取今日课件哦 ↑</span></center>**\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414ed1ba-b8ea-41fc-b78c-48de321f722e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5264e6-241d-431e-b6c2-0b0ced7619ee",
   "metadata": {},
   "source": [
    "## 二、GLM4 API调用指南与关键参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22f6cb-b9cd-45cb-bd02-40cd8d58808a",
   "metadata": {},
   "source": [
    "### 1. 基于chat.completions完成对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fdbfe18-c569-4087-aa07-7abaa660e2bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from zhipuai import ZhipuAI\n",
    "from IPython.display import display, Code, Markdown\n",
    "\n",
    "api_key = os.getenv(\"ZHIPU_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a93ec-0fbb-40ac-a662-eae275d610ed",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在上一小节中，我们已经顺利完成智谱AI账号注册，并获取GLM模型API-KEY，同时完成了本地调用测试。本节我们将开始着手使用GLM-4模型，并详细介绍GLM-4调用函数参数及模型的多角色对话系统。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de69b3c-d026-49b9-9875-ce1a6d9c51b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你好👋！我是人工智能助手智谱清言，可以叫我小智🤖，很高兴见到你，欢迎问我任何问题。' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "client = ZhipuAI(api_key=api_key) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"你好\"}\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee433cda-147f-4657-af8f-3a898cb3746f",
   "metadata": {},
   "source": [
    "1. **Create (create)**: 表面上是生成文本的主要方法，**但实际是发起对话的核心函数**。用户通过提供一系列参数（如模型、提示信息、温度等）来获取模型生成的文本。\n",
    "\n",
    "2. **Retrieve (retrieve)**: 这个函数用于获取之前生成的完成任务的详细信息。通过传递一个特定的完成任务的ID，可以查询该任务的具体内容、状态等信息。这对于跟踪和分析模型的响应非常有用。\n",
    "   \n",
    "3. **List (list)**: 这个功能允许用户列出账户下的历史完成记录。可以指定某个时间段或使用其他过滤条件，以便查找特定的完成任务。这对于管理和审查生成的内容很有帮助。\n",
    "   \n",
    "4. **Stream (stream)**: 这个函数用于实时接收模型生成的数据。在一些需要实时交互的应用场景中非常有用，比如实时聊天机器人或其他需要即时反馈的服务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1802d-6520-4ab3-98d0-6549d03c4f1e",
   "metadata": {},
   "source": [
    "大模型的对话功能是大模型开发流程中最为核心的要点，**调用一次create就是发起一次对话**，当我们需要多次与大模型进行对话时，我们就需要多次调取create——"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00189930-7054-49c8-bf98-37ef629f9b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='大语言模型（Large Language Model，简称LLM）是一种基于深度学习技术的语言模型。这种模型通过学习大量的文本数据，能够理解和生成自然语言文本。大语言模型的核心在于其庞大的规模和复杂的结构，它们通常拥有数十亿甚至更多的参数，并使用深度神经网络捕捉语言中的语义、语法和上下文关系。\\n\\n大语言模型不是针对单一的自然语言处理任务（如情感分析、命名实体识别等）进行训练的，而是通过自监督学习或半监督学习的方式，在多种语言任务上具备广泛的适用性。这种模型能够在没有特定训练的情况下，理解和生成文本，显示出对人类语言强大的理解和生成能力。\\n\\n在应用上，大语言模型不仅可以处理传统的自然语言任务，如文本分类、问答、对话等，还能支持多模态应用，比如与音频、图像、视频等结合的场景。它们的代表包括GPT、GPT-4、PaLM2、Gemini、文心ERNIE等。\\n\\n总体来说，大语言模型是当前人工智能领域中的一项重要技术，它推动了自然语言处理（NLP）领域的巨大进步，并在多个行业和场景中展现出广泛的应用潜力。' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "response_1 = client.chat.completions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"请问什么是大语言模型？\"}\n",
    "    ],\n",
    ")\n",
    "print(response_1.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1601c9ab-7215-4ab9-9137-65598cd6647f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='对不起，由于您的问题中没有具体指明“它”是什么，我无法直接给出具体的回答。不过，如果您是在询问某种技术或工具如何为人们的生活和工作带来便利，我可以举例说明。\\n\\n例如，如果我们谈论的是“互联网”，那么它为人们的生活和工作带来了极大的便利。在生活方面，互联网使得信息获取变得前所未有地容易，人们可以通过搜索引擎迅速找到所需的信息。此外，网上购物让人们可以足不出户就能购买到各种商品；社交媒体则让亲朋好友之间的沟通变得更加频繁和便捷。\\n\\n在工作方面，互联网的便利性体现在远程工作、在线会议和云计算服务等。例如，因为有了互联网，人们可以在家办公，通过视频会议软件与全球的同事协作，这提高了工作效率，也增加了工作的灵活性。\\n\\n如果您指的是其他的技术或概念，请提供更多的信息，我将提供更具体的例子。' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "response_2 = client.chat.completions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"你提到它能为人们的生活和工作带来便利，它是什么？你可以举个例子吗？\"}\n",
    "    ],\n",
    ")\n",
    "print(response_2.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad3c61e-4121-4e27-8533-1be2d2e29d4d",
   "metadata": {},
   "source": [
    "很明显，模型并不记得之前的信息，对话与对话之间是相互独立的。如果我们想让模型记得之前的信息，就需要将上一个create方法产出的结果输入到下一个create方法中。所以在大模型开发的流程中，**对话功能是嵌套的逻辑、而不是线性的逻辑**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "706c2eb3-1270-4a24-ad07-4b6d13bf313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_ = response_1.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd0b1e4d-1f4b-4aa1-8d10-bbe2dcfeb570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大语言模型（Large Language Model，简称LLM）是一种基于深度学习技术的语言模型。这种模型通过学习大量的文本数据，能够理解和生成自然语言文本。大语言模型的核心在于其庞大的规模和复杂的结构，它们通常拥有数十亿甚至更多的参数，并使用深度神经网络捕捉语言中的语义、语法和上下文关系。\\n\\n大语言模型不是针对单一的自然语言处理任务（如情感分析、命名实体识别等）进行训练的，而是通过自监督学习或半监督学习的方式，在多种语言任务上具备广泛的适用性。这种模型能够在没有特定训练的情况下，理解和生成文本，显示出对人类语言强大的理解和生成能力。\\n\\n在应用上，大语言模型不仅可以处理传统的自然语言任务，如文本分类、问答、对话等，还能支持多模态应用，比如与音频、图像、视频等结合的场景。它们的代表包括GPT、GPT-4、PaLM2、Gemini、文心ERNIE等。\\n\\n总体来说，大语言模型是当前人工智能领域中的一项重要技术，它推动了自然语言处理（NLP）领域的巨大进步，并在多个行业和场景中展现出广泛的应用潜力。'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2856c8f-db45-42a6-a2a8-e8d8c328607f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='大语言模型（LLM）能为人们的生活和工作带来便利的原因在于其能够理解和生成自然语言，从而在各种场景中提供智能化服务。以下是一些具体的例子：\\n\\n1. **智能客服**：在服务业，大语言模型可以充当智能客服，为顾客提供24/7的在线咨询服务。例如，当消费者在电商平台购物时，如果有关于商品信息、物流状态或退换货政策的问题，大语言模型可以实时回答，提高服务效率，减少人力成本。\\n\\n   例子：当用户询问“我的包裹什么时候能送达？”时，大语言模型可以即时检索物流信息并回复：“您的包裹目前已到达[城市名]，预计将在明天下午送达，请您耐心等待。”\\n\\n2. **教育辅助**：在教育领域，大语言模型可以帮助学生和老师。例如，它可以辅助学生进行写作，提供写作建议和修改意见，甚至能生成范文供学生参考。\\n\\n   例子：当学生写作文时，模型可以提供如下建议：“你的文章结构清晰，但在论述部分可以加入更多具体的例子来增强说服力，比如可以考虑引入[相关案例]。”\\n\\n3. **内容创作**：对于媒体工作者和内容创作者，大语言模型可以辅助创作过程，提供写作灵感，甚至生成初稿。\\n\\n   例子：记者在撰写关于科技新品的报道时，大语言模型可以帮助生成概述：“这款新推出的智能手机采用了业界领先的[技术名]，在保持轻薄设计的同时，电池续航能力显著提升。”\\n\\n4. **编程助手**：对于软件开发者，大语言模型可以根据开发者的描述生成代码片段，或帮助解决编程过程中的问题。\\n\\n   例子：当程序员描述一个功能需求时，模型可以提供相应的代码模板：“你想要实现一个列表的排序功能，以下是使用Python的sorted函数的一个示例代码…”\\n\\n5. **个人助理**：在日常生活中，大语言模型可以作为个人助理，帮助用户管理日程、设置提醒、搜索信息等。\\n\\n   例子：用户可以询问：“我下周五晚上的日程安排是什么？”模型则会查找日历并回复：“你下周五晚上有一个晚餐约会，地点在[餐厅名]。”\\n\\n通过这些例子，我们可以看到大语言模型在提高效率、减少工作量、提供个性化服务等方面为人们的生活和工作带来了极大的便利。随着技术的不断进步和应用的深入，大语言模型的潜力将会在更多领域得到挖掘。' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": memory_ + \"你提到它能为人们的生活和工作带来便利，它是什么？你可以举个例子吗？\"}\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c17977-1215-4663-91d3-87bb4f8e4d16",
   "metadata": {},
   "source": [
    "#### 1.GLM多角色对话系统解释"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7964bc6a-3850-4467-8529-3c30b4057113",
   "metadata": {},
   "source": [
    "&emsp;&emsp;时至今日，多角色对话基本上已经成了顶尖大模型的标配。正是基于多角色对话这一基础技术架构，大模型才能非常灵活的实现各类对话需求，甚至多角色对话也是更高效的实现Function calling的基础，而后者则是整个Agent开发的基石。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292ef57c-5d6a-42fa-8d75-cf1772620e3d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;那什么是多角色对话呢？简而言之就是将用户和大模型之间的“私聊”变为“群聊”，在用户和大模型这两个角色基础之上，进一步增加“系统”和“工具”这两个角色。尽管最终目的都是为了能完成大模型完成和用户的之间对话，但在对话过程中添加一些额外角色，确实能够更好的引导大模型完成对话。例如对话系统中增加的“系统”这一角色，可以为本次对话增加基本背景信息、对大模型进行角色身份设置等，相当于是设置本场对话的基本规则和信息；而对话系统中的“工具”这一角色，则相当于是大模型的拓展工具箱，当大模型无法回答当前问题的时候（例如用户希望查询当前即时天气），就可以向工具求助，而如果这个“工具”角色能够查到当前天气，则会“告诉”大模型当前天气情况，大模型在接收到了当前天气情况之后再告诉用户。如此一来，大模型便可以更加高效便捷的完成对话任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afad6cd-7d89-4eeb-bd5e-fc1bc9db051b",
   "metadata": {},
   "source": [
    "> 尽管多角色对话系统能够极大程度提高大模型的对话可用性，但并非所有模型都有能力进行多角色对话——往往只有推理能力较强的大模型才能够非常顺利的进行多角色对话。对于ChatGLM系列模型来说，也正是发布到了第三代，才正式引入多角色对话系统。而相比之下GPT系列模型，从ChatGPT（GPT-3.5）开始一直都是多角色对话模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed22a2-2458-4a84-a66e-164d8e8c2482",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而实际执行过程中，多角色对话的过程核心是依靠messages参数来实现的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7749050c-d3db-46e8-8480-bda33946d8c1",
   "metadata": {},
   "source": [
    "#### 2.messages功能综述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e8a68-5827-4297-8856-08b1b808be99",
   "metadata": {},
   "source": [
    "&emsp;&emsp;总的来说，messages是一种用于描述ChatCompletion模型和用户之间通信信息的高级抽象，也是支撑多角色对话系统的关键，从表示形式上来说，一个messages是一个列表，包含多个字典，而每个字典都是一条消息，其中，一条消息由包含两个键值对（即每个字典都包含两个键值对），第一个键值对用于表示消息发送者，其中第一个Key为字符串'role'，Value为参与对话的角色名称，或者可以理解为本条消息的作者或消息发送人名称，第二个键值对表示具体消息内容，Key为字符串'content'，Value为具体的消息内容，用字符串表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d79f35b3-b951-4797-bfa1-53165eac90ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = ZhipuAI(api_key=api_key) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  \n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18e0d9c5-f703-4d0c-910b-2c4ffa232362",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "机器学习是计算机科学和人工智能的一个分支，它涉及开发算法和统计模型，使得计算机系统能够基于数据进行自我学习和改进，而无需进行显式的编程。简单来说，机器学习就是使计算机能够从经验中学习，并据此进行预测或决策的技术。\n",
       "\n",
       "在机器学习中，系统通过分析大量的数据样本，从中识别出数据之间的模式和规律，然后使用这些模式来对新的数据进行预测或分类。这个过程通常分为几个步骤：\n",
       "\n",
       "1. 数据收集：首先需要收集大量的数据，这些数据可以是图片、文本、声音或者其他任何形式。\n",
       "2. 数据预处理：收集到的数据需要进行清洗和格式化，以便算法能够更好地处理。\n",
       "3. 特征提取：从数据中提取关键的特征，这些特征将用于训练模型。\n",
       "4. 模型训练：使用算法在训练数据集上进行学习，建立一个能够捕捉数据特征的模型。\n",
       "5. 模型评估：使用测试数据集来评估模型的性能，确保模型能够泛化到未见过的数据。\n",
       "6. 参数调优：根据模型评估的结果调整模型参数，以优化其性能。\n",
       "\n",
       "机器学习的方法可以大致分为以下几类：\n",
       "\n",
       "- **有监督学习**：在这种方法中，系统使用标记过的数据进行学习，即每个数据样本都有一个对应的标签或目标值。常见的有监督学习任务包括分类和回归。\n",
       "- **无监督学习**：在此类方法中，系统分析未标记的数据，试图发现数据内在的结构或规律，常见的任务包括聚类和降维。\n",
       "- **半监督学习**：结合了有监督和无监督学习，系统同时使用标记和未标记的数据进行学习。\n",
       "- **强化学习**：这是一种通过试错来学习的方法，系统（智能体）在环境中采取行动，并根据行动的结果（奖励或惩罚）来调整其行为。\n",
       "\n",
       "机器学习已经在许多领域取得了显著的应用成果，包括语音识别、图像处理、自然语言处理、医疗诊断、金融预测等。随着计算能力的提高和大数据的出现，机器学习的发展前景广阔，正在逐渐成为推动未来科技进步的重要力量。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5988df-1504-4c66-92b8-97c0aca5a848",
   "metadata": {},
   "source": [
    "例如上述示例中的messages就总共包含一条信息，即一个一个名为user的角色发送了一条名为'请问什么是机器学习？'的消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b91d7120-faf4-49c5-bced-2b89d16d00d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5623458-ea0a-4e59-8837-051b251e8cae",
   "metadata": {},
   "source": [
    "而同时，返回的message结果也是一个“字典”，并且也包含了信息的发送方和具体信息内容，不难看出，此时返回的message发送方是一个名为'assistant'的角色，而具体内容则是一段关于什么是机器学习的描述："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd6d4598-bb8d-4438-b28d-4fa87e2a3e87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionMessage(content='机器学习是计算机科学和人工智能的一个分支，它涉及开发算法和统计模型，使得计算机系统能够基于数据进行自我学习和改进，而无需进行显式的编程。简单来说，机器学习就是使计算机能够从经验中学习，并据此进行预测或决策的技术。\\n\\n在机器学习中，系统通过分析大量的数据样本，从中识别出数据之间的模式和规律，然后使用这些模式来对新的数据进行预测或分类。这个过程通常分为几个步骤：\\n\\n1. 数据收集：首先需要收集大量的数据，这些数据可以是图片、文本、声音或者其他任何形式。\\n2. 数据预处理：收集到的数据需要进行清洗和格式化，以便算法能够更好地处理。\\n3. 特征提取：从数据中提取关键的特征，这些特征将用于训练模型。\\n4. 模型训练：使用算法在训练数据集上进行学习，建立一个能够捕捉数据特征的模型。\\n5. 模型评估：使用测试数据集来评估模型的性能，确保模型能够泛化到未见过的数据。\\n6. 参数调优：根据模型评估的结果调整模型参数，以优化其性能。\\n\\n机器学习的方法可以大致分为以下几类：\\n\\n- **有监督学习**：在这种方法中，系统使用标记过的数据进行学习，即每个数据样本都有一个对应的标签或目标值。常见的有监督学习任务包括分类和回归。\\n- **无监督学习**：在此类方法中，系统分析未标记的数据，试图发现数据内在的结构或规律，常见的任务包括聚类和降维。\\n- **半监督学习**：结合了有监督和无监督学习，系统同时使用标记和未标记的数据进行学习。\\n- **强化学习**：这是一种通过试错来学习的方法，系统（智能体）在环境中采取行动，并根据行动的结果（奖励或惩罚）来调整其行为。\\n\\n机器学习已经在许多领域取得了显著的应用成果，包括语音识别、图像处理、自然语言处理、医疗诊断、金融预测等。随着计算能力的提高和大数据的出现，机器学习的发展前景广阔，正在逐渐成为推动未来科技进步的重要力量。', role='assistant', tool_calls=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32bbae4-20b0-44e7-bd38-c5e16c2538d6",
   "metadata": {},
   "source": [
    "由此不难看出，对话Chat模型的每个对话任务都是通过输入和输出message来完成的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6318b509-b040-47e7-a720-4baa1b5e20e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.messages中的角色划分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95b9e1-2075-4673-8de0-95999dbcdf10",
   "metadata": {},
   "source": [
    "- user role和assistant role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a9e0f-504f-4577-aa7f-20900e949e67",
   "metadata": {},
   "source": [
    "&emsp;&emsp;那么接下来的问题就是，在实际调用Chat模型进行对话时，messages中的role应该如何设置呢？从上述极简的对话示例中能够看出，一个最简单的对话就是我们扮演user（用户）这个角色（'role':'user'），然后在content中输入我们的问题并等待模型回答。而模型在实际回答过程中，也会扮演一个名为assistant（助手）这个角色（'role':'assistant'）进行回答，这里的user和assistant是具有明确含义的字符串，即如果一条信息的role是user，则表明这是用户向模型发送的聊天信息，相当于是Completion模型中的prompt，而如果一条信息的role是assistant，则表示这是当前模型围绕某条用户信息做出的回应，相当于是相当于是Completion模型中的text。需要注意的是，在messages参数中，我们是不能给自己或者模型自定义其他名称的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701aa0c-9a1a-448b-b344-d22e61e2553b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;很明显，基于这样的一个定义的规则，最简单的Chat模型的调用方法就是在messages参数中设置一条role为user的参数，在content中输入聊天的内容，而模型则会根据这条用户输入给模型的消息进行回答，类似于此前我们向模型提问“请问什么是机器学习？”这种提问方式:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38a45c48-e289-42d5-94f3-b91e0d3eec53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = ZhipuAI(api_key=api_key) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  \n",
    "    messages=[\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c6d89c3-01bd-4238-ad18-2dbf949fd897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机器学习是一门研究如何让计算机从数据中学习，并据此进行预测或决策的学科。它是人工智能的一个重要分支，致力于通过算法和统计模型让计算机系统利用已有的数据进行学习，从而获取新的知识或技能。\\n\\n在机器学习的框架下，计算机可以通过以下方式模拟人类学习行为：\\n\\n1. **有监督学习（Supervised Learning）**：在这种模式下，计算机通过分析已标记的数据（即每个数据点都有一个对应的输出标签）来学习。例如，通过分析一系列图片及其对应的标签（如“猫”或“狗”）来训练一个图像识别模型。\\n\\n2. **无监督学习（Unsupervised Learning）**：在无监督学习中，计算机处理的数据没有附加的标签。它尝试通过识别数据中的模式或结构来进行学习。聚类算法就是一个例子，它会将相似的数据点归为一类。\\n\\n3. **半监督学习（Semi-supervised Learning）**：这种学习方法介于有监督学习和无监督学习之间，其中一部分数据是标记的，而另一部分则不是。\\n\\n机器学习的关键要素包括：\\n\\n- **输入数据**：用于训练模型的数据集。\\n- **预期输出实例**：在有监督学习中，这是与输入数据对应的正确输出。\\n- **衡量算法效果的方法**：用于评估模型性能的指标，如准确率、召回率等。\\n\\n机器学习的应用范围非常广泛，包括但不限于图像识别、语音识别、自然语言处理、推荐系统、医疗诊断、金融预测等领域。\\n\\n简而言之，机器学习是一种使计算机能够通过经验改进其性能的技术，它正在改变我们生活的各个方面，并推动科技进步。'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36330d8a-a2fd-41f8-a2de-58ea36bb575c",
   "metadata": {},
   "source": [
    "不过需要注意的是，尽管一个messages可以包含多条信息，但模型只会对于最后一条用户信息进行回答，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3b0a654b-6f1c-4b96-832e-4cee0f8aa035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = ZhipuAI(api_key=api_key) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  \n",
    "    messages=[\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"},\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是决策树算法？\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d10b6719-c865-4035-a5ec-46d99b2d1090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'决策树算法是一种常用的机器学习算法，它模仿人类决策过程，通过一系列的问题（即特征）来对数据进行分类或回归分析。决策树由节点和边组成，每个节点代表一个特征或属性，边代表该特征的某个取值，叶节点代表最终的分类或预测结果。\\n\\n具体来说，决策树的工作原理如下：\\n\\n1. **根节点**：树的最顶端节点，代表整个数据集。\\n2. **内部节点**：树中的非叶节点，每个节点都对应数据集中的一个特征。节点会基于这个特征的不同取值来划分数据集。\\n3. **叶节点**：树的最底层节点，表示分类结果或回归值。\\n4. **边**：连接节点的线，表示特征的某个取值。\\n\\n在构建决策树时，算法会自动选择最优的特征进行分割，通常使用信息增益（ID3算法）、增益率（C4.5算法）或基尼不纯度（CART算法）等准则来评估特征的好坏。\\n\\n决策树算法的优点包括：\\n\\n- 易于理解和解释。\\n- 可以处理数值和分类数据。\\n- 可以处理多路输出问题。\\n- 不需要大量的数据预处理。\\n\\n缺点包括：\\n\\n- 容易过拟合，特别是在数据特征较多时。\\n- 对于类别不平衡的数据，分类决策树可能会偏向于多数类。\\n- 对于连续值预测，可能不如其他算法精确。\\n\\n决策树在许多领域都有应用，如医学诊断、信用评分、股票市场预测等。'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364fed2-8988-408a-a6d1-fc1973c63a4e",
   "metadata": {},
   "source": [
    "也就是说，assistant消息和role消息是一一对应的，而且在一般情况下，assistant消息只会围绕messages参数中的最后一个role信息进行回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3653d-8fa5-4eb2-a308-9c0eb743d75b",
   "metadata": {},
   "source": [
    "- system role用于身份设定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed6040-e63d-4d4e-aa55-997d6dfcfcee",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过，值得一提的是，user和assistant的这种提问方式尽管足够清晰，但往往形式上不够丰富，例如在实践中人们发现，给聊天机器人进行一个身份设置，其实是非常有效的引导模型创作我们想要的结果的方法，例如如果我们希望获得一个关于“什么是机器学习？”更加严谨且丰富的答案，我们可以以“假设你是一名资深的计算机系大学教授”为模型进行身份设置，例如我们可以以如下方式向模型进行提问："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "372ec330-3e1c-4f3e-a055-6a4c2efcf845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = ZhipuAI(api_key=api_key) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  \n",
    "    messages=[\n",
    "    {\"role\": \"user\", \"content\": \"假设你是一名资深的计算机系大学教授，请帮我回答，什么是机器学习？\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1bcc4499-427d-41a1-ad0e-4951905906f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机器学习是计算机科学中的一个分支，它致力于开发和应用算法让计算机系统能够基于数据进行自我学习和改进，而无需进行显式的编程。在机器学习中，我们让计算机通过经验（即数据）学习，从而使它可以对未知数据进行预测或决策。\\n\\n简单来说，机器学习可以看作是让计算机模拟人类学习过程的一种技术。它涉及统计学、概率论、数学优化、算法理论等多个领域。在实际应用中，机器学习算法可以从大量的数据中找出潜在的模式，并用这些模式来对新数据做出预测或分类。\\n\\n机器学习可以分为几种主要类型：\\n\\n1. **监督学习（Supervised Learning）**：在这种模式下，算法从标记过的训练数据中学习，即每个样本都有一个对应的输出标签。监督学习的目标是训练出一个模型，使其能够对新的、未见过的数据进行准确的预测。\\n\\n2. **无监督学习（Unsupervised Learning）**：在无监督学习中，算法处理的是没有标记的数据。它的目标是发现数据中的结构或模式，如通过聚类算法将相似的数据点分组。\\n\\n3. **半监督学习（Semi-supervised Learning）**：这种学习方法介于监督学习和无监督学习之间，其中一部分数据是标记的，而另一部分则没有。\\n\\n4. **强化学习（Reinforcement Learning）**：这是一种通过奖励和惩罚机制来指导算法的学习方法。系统（通常被称为智能体）在环境中采取行动，并根据行动的结果来调整策略，以最大化累积奖励。\\n\\n机器学习在各个领域都有广泛的应用，包括但不限于图像识别、语音识别、自然语言处理、医疗诊断、推荐系统等。随着技术的不断进步，机器学习已经成为了现代生活中不可或缺的一部分。'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c49e57-4c8f-4564-b5bc-3d59e5c73c80",
   "metadata": {},
   "source": [
    "不难看出，此时模型的回答就变得更加详细和严谨，更像一名“大学教授”的语气风格，也同时说明我们对模型进行的身份设定是切实有效的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da050703-b7b8-409e-ad79-f3d76c6950e2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而在completion.create函数中，还有另外一种非常便捷的对模型进行身份设置的方法，即使用system role，即我们可以使用如下方式为模型进行“大学教授”身份设定："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d6ab4972-3105-48a8-8651-9903007b1866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = ZhipuAI(api_key=api_key) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  \n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": \"你是一名资深的计算机系大学教授\"},\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "56631d65-e04b-4b76-99e6-71fb7ebe02ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机器学习（Machine Learning, ML）是计算机科学的一个分支，主要研究如何让计算机从数据或经验中学习，并据此进行预测或决策。简单来说，机器学习就是用算法来解析数据、从中学习、然后做出决策或预测。\\n\\n机器学习可以分为几种主要类型：\\n\\n1. **监督学习（Supervised Learning）**：在这种模式下，算法从标记过的训练数据中学习，然后用学到的知识来预测新的、未标记的数据。例如，通过分析过去的房价数据来预测未来的房价。\\n\\n2. **无监督学习（Unsupervised Learning）**：在无监督学习中，算法处理没有标记的数据，尝试自己找出数据中的结构或模式。聚类和关联规则学习是两个常见的例子。\\n\\n3. **半监督学习（Semi-supervised Learning）**：这种方法结合了监督学习和无监督学习，其中一部分数据是标记的，但大部分数据是未标记的。\\n\\n4. **强化学习（Reinforcement Learning）**：这是一种通过奖励和惩罚机制来学习如何完成特定任务的方法。在这种方法中，算法（通常被称为“智能体”）通过与环境互动来学习如何在给定情境下做出最优决策。\\n\\n机器学习在许多领域都有应用，包括自然语言处理、图像识别、推荐系统、医疗诊断、金融预测等。随着技术的进步和数据量的增加，机器学习变得越来越重要，是现代计算机科学和人工智能领域的关键技术之一。'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64858e2f-c7cd-477a-b7d7-85c92fac60af",
   "metadata": {},
   "source": [
    "&emsp;&emsp;能够看出，这里我们在原有消息之前，新增一条消息{\"role\": \"system\", \"content\": \"你是一名资深的计算机系大学教授\"}，也能起到设定模型身份的作用。而这条消息的实际含义是，以system的身份发送一条消息，消息内容为“你是一名资深的计算机系大学教授”。这里的system就是messages参数的role可以选取的第三个字符串，意为该消息为一条系统消息。相比用户消息，系统消息有以下几点需要注意，其一是系统消息的实际作用是给整个对话系统进行背景设置，不同的背景设置会极大程度影响后续对话过程中模型的输出结果，例如如果系统设置为“你是一位资深医学专家”，那么接下来系统在进行回答医学领域相关问题时则会引用大量医学术语，而如果系统设置为“你是一位资深喜剧演员”，那么接下来系统进行的回答则会更加风趣幽默："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "852c41d8-9e59-48ae-97a5-e232c68fd0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = ZhipuAI(api_key=api_key) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  \n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": \"你是一名资深的喜剧演员\"},\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4da05b0f-7b7c-46ab-98f4-940b85cdbabc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'哦，作为一个喜剧演员，我会这样解释机器学习：\\n\\n机器学习嘛，就像是你的智能手机试图学会如何像人类一样忘记事情。你知道的，我们人类有时候会忘记事情，但手机呢？它们总是记得每一个小细节，对吧？机器学习就是让这些设备通过观察和经验来学习，就像小孩子学习不要把玩具扔进鱼缸一样。不过，机器学习的目标是让这些机器变得更聪明，而不是像我们一样忘记把车钥匙放在哪里了。\\n\\n开个玩笑啦。实际上，机器学习是人工智能的一个分支，它让计算机系统能够从数据中学习并改进，而无需人为编程。它通过算法分析数据、识别模式，并基于这些信息做出预测或决策。简单来说，就是让机器通过经验变得更聪明。'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7de4fc-6a8a-4cd1-a3a4-b8cf0a31e5ef",
   "metadata": {},
   "source": [
    "这里需要重点注意，通过system_message进行身份设置对于GLM4模型效果较好，而对于GLM3模型来说效果非常不稳定："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e1dd750-d210-4f98-a634-c583bcc13755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = ZhipuAI(api_key=api_key) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-3-turbo\",  \n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": \"你是一名资深的喜剧演员\"},\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "99e5ca77-3fb6-4fce-9984-0251ee3c2247",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机器学习是一门人工智能（AI）的分支，主要研究如何让计算机从数据或经验中学习，并据此进行预测或决策。简单来说，机器学习就是用算法来解析数据、从中学习、然后做出决策或预测。\\n\\n机器学习可以分为几种主要类型：\\n\\n1. **监督学习（Supervised Learning）**: 在这种模式下，算法从标记过的训练数据中学习，然后用学到的知识来预测新的、未标记的数据。例如，通过分析过去的房价数据来预测未来的房价。\\n\\n2. **无监督学习（Unsupervised Learning）**: 算法在没有标记的数据集上进行训练，试图自己找出数据内在的结构或规律。聚类和关联规则学习就是两个常见的例子。\\n\\n3. **半监督学习（Semi-supervised Learning）**: 这是一种介于监督学习和无监督学习之间的方法，其中一部分数据是标记的，但大部分数据是未标记的。\\n\\n4. **强化学习（Reinforcement Learning）**: 在这种类型中，算法（通常被称为“智能体”）通过与环境进行交互来学习如何完成特定任务。智能体会获得奖励或惩罚，以便调整其行为。\\n\\n机器学习在各个领域都有广泛的应用，包括自然语言处理、图像识别、推荐系统、金融预测等。\\n\\n机器学习还分为传统机器学习和深度学习。传统机器学习通常使用简单的算法和特征，而深度学习则使用多层神经网络和大量的特征。深度学习在近年来取得了很大的成功，尤其是在图像和语音识别等领域。\\n\\n值得注意的是，机器学习并不意味着“自主学习”。机器学习模型通常需要大量的数据和计算资源，而且它们的学习结果完全取决于输入的数据。因此，确保数据的质量和多样性非常重要。\\n\\n在中国，机器学习和人工智能也得到了广泛的关注和研究，许多企业和研究机构都在这方面取得了显著的进展。'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e50fd-b248-40d0-bc5d-114ad6663bc0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而第二方面需要注意的则是，当messages中只包含一条system消息时，GLM4模型会直接报错："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b6edc66-5002-4f62-992f-5809cc42f4d5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "APIRequestFailedError",
     "evalue": "Error code: 400, with error text {\"error\":{\"code\":\"1214\",\"message\":\"messages 参数非法。请检查文档。\"}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRequestFailedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mglm-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m你是一名资深的喜剧演员\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\openenv\\lib\\site-packages\\zhipuai\\api_resource\\chat\\completions.py:48\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, model, request_id, do_sample, stream, temperature, top_p, max_tokens, seed, messages, stop, sensitive_word_check, tools, tool_choice, extra_headers, disable_strict_validation, timeout)\u001b[0m\n\u001b[0;32m     46\u001b[0m     _cast_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m     47\u001b[0m     _stream_cls \u001b[38;5;241m=\u001b[39m StreamResponse[\u001b[38;5;28mobject\u001b[39m]\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequest_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdo_sample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msensitive_word_check\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msensitive_word_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_user_request_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_cast_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_stream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\openenv\\lib\\site-packages\\zhipuai\\core\\_http_client.py:292\u001b[0m, in \u001b[0;36mHttpClient.post\u001b[1;34m(self, path, body, cast_type, options, files, enable_stream, stream_cls)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m         path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m         stream_cls: \u001b[38;5;28mtype\u001b[39m[StreamResponse[Any]] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m StreamResponse:\n\u001b[0;32m    289\u001b[0m     opts \u001b[38;5;241m=\u001b[39m ClientRequestParam\u001b[38;5;241m.\u001b[39mconstruct(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mmake_httpx_files(files), url\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m    290\u001b[0m                                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m--> 292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_stream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_stream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\openenv\\lib\\site-packages\\zhipuai\\core\\_http_client.py:251\u001b[0m, in \u001b[0;36mHttpClient.request\u001b[1;34m(self, cast_type, params, enable_stream, stream_cls)\u001b[0m\n\u001b[0;32m    249\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# raise err\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[1;31mAPIRequestFailedError\u001b[0m: Error code: 400, with error text {\"error\":{\"code\":\"1214\",\"message\":\"messages 参数非法。请检查文档。\"}}"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  \n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"你是一名资深的喜剧演员\"},\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303cf7ba-7fa0-488a-8215-863f4e2ee09a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;第三方面需要注意的是，如果我们需要根据system系统信息对系统进行设置，然后再提问，那么先system消息再user消息的顺序就变得非常重要，例如还是上面的例子，还是希望以喜剧演员的身份介绍机器学习，但我们调换了system消息和user消息的顺序，那么会发现，system消息的作用就会失效，这点和GPT系列模型完全一样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e634b494-53f3-4d47-9cb9-6dd93e0de38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  \n",
    "    messages=[\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"},\n",
    "    {\"role\": \"system\", \"content\": \"你是一名资深的喜剧演员\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a27cdd26-8f49-4eae-b223-4605e34eb869",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机器学习是一门人工智能（AI）的分支，主要研究如何让计算机从数据或经验中学习，并据此进行预测或决策。简单来说，机器学习就是用算法来解析数据、从中学习、然后做出决策或预测。\\n\\n机器学习可以分为几种主要类型：\\n\\n1. **监督学习（Supervised Learning）**：在这种模式下，算法从标记过的训练数据中学习，然后能够对新的、未见过的数据进行预测或分类。\\n\\n2. **无监督学习（Unsupervised Learning）**：在这种情况下，算法从没有标记的数据中学习，寻找数据中的模式或结构。\\n\\n3. **半监督学习（Semi-supervised Learning）**：这种类型的机器学习介于监督学习和无监督学习之间，其中一部分数据是标记的，但大部分数据是未标记的。\\n\\n4. **强化学习（Reinforcement Learning）**：这是一种通过奖励和惩罚机制来让算法学习如何完成特定任务的方法。\\n\\n机器学习在各个领域都有广泛的应用，包括但不限于图像识别、语音识别、自然语言处理、医疗诊断、推荐系统等。它是现代技术和社会发展的一个重要组成部分，有助于提高效率、准确性和创新能力。'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c5aa7-a016-412f-8cb0-bbcef1ae9e2a",
   "metadata": {},
   "source": [
    "此时会发现，模型还是能解答“请问什么是机器学习？”这个问题，但却没有正确接受“你是一名资深喜剧演员”这个设定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606fc67b-8b2f-43fe-aa67-d2514211701f",
   "metadata": {},
   "source": [
    "- 借助system messages设置聊天背景信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a4462-12a1-41ec-9e0c-9e89455e4feb",
   "metadata": {},
   "source": [
    "&emsp;&emsp;除了可以借助system消息非常便捷的进行提示模板的设计之外，还有一个非常常见的system role的使用方法，就是借助system消息进行聊天背景信息的设定，很多时候我们可以在system消息中输入一段长文本，这段长文本将在聊天开始之前输入到系统中，而在之后的聊天中，即可让assistant围绕这个长文本进行回答，这是一种最简单的实现大语言模型围绕本地知识库进行问答的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf2ee44-ca2a-4f31-ae40-8a46657826ce",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里我们在system消息中输入一段关于虚拟人物“陈明”的个人简介，而在之后的提问中，user和assistant将可以自由的围绕这段输入的背景信息进行问答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a984b181-ce34-40af-8566-cecbfa7970b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = '陈明，男，1973年7月15日出生于中国福建省厦门市。\\\n",
    "        1991年毕业于厦门大学电子科学与技术系，继而于1998年在北京大学获得信息技术博士学位。\\\n",
    "        毕业后的陈明在硅谷的一家著名科技公司工作了五年，专注于人工智能和机器学习的研发。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9326d698-553f-4a31-bb57-bb9be5604d5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  \n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": text},\n",
    "    {\"role\": \"user\", \"content\": '请问陈明是那一年出生？'}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "159082db-7ed3-400e-a7f5-df090cd18a85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'陈明是1973年7月15日出生的。'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f52469e-ce28-467a-bf52-3825aefb3580",
   "metadata": {},
   "source": [
    "能够看出，这段背景背景信息能够被模型学习并以此进行特定问题的回答。这其实就是一种非常简单的围绕本地知识进行问答的实现形式，不过需要注意的是，system role输入的信息也算是输入给模型的信息，因此受限于大语言模型的最大输入信息长度，单独借助system role在ChatCompletion.create函数中输入背景信息并不能真正意义上实现高度定制化、超大规模文本的本地知识库问答。但是，如果围绕着超大规模本地文本知识库先进行基于滑动窗口的文本切分，以确保切分后的小文本段落满足Max tokens要求，并且配合Embedding过程进行user问题和短文本的实时匹配，再把每个user问题匹配的关联度最高的文本以system消息的形式输入到模型中，再进行回答，则可以非常高效并且准确的实现本地知识库问答。而在这个过程中，借助system role进行背景文字的输入就非常基本的技术手段。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dd3aea-7fab-48d5-af8b-a8f987f2ccc1",
   "metadata": {},
   "source": [
    "### 2. chat.completions.create关键参数详解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c33855-821d-4bda-96f1-c066605b1320",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来围绕chat.completions.create函数的关键参数进行解释："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac232cf-8d6f-4f51-939f-6cb3e41b8702",
   "metadata": {},
   "source": [
    "| 参数名称       | 类型 | 是否必填   | 参数解释 |\n",
    "| ----------- | ------- | ------------ | ------------------------------------------------------------ |\n",
    "| model       | String           | 是   | 所要调用的模型编码                                           |\n",
    "| messages    | List<Object>     | 是   | 调用语言模型时，将当前对话信息列表作为提示输入给模型， 按照 `{\"role\": \"user\", \"content\": \"你好\"}` 的json 数组形式进行传参； 可能的消息类型包括 System message、User message、Assistant message 和 Tool message。 |\n",
    "| request_id  | String           | 否   | 由用户端传参，需保证唯一性；用于区分每次请求的唯一标识，用户端不传时平台会默认生成。 |\n",
    "| do_sample   | Boolean          | 否   | do_sample 为 true 时启用采样策略，do_sample 为 false 时采样策略 temperature、top_p 将不生效 |\n",
    "| stream      | Boolean          | 否   | 使用同步调用时，此参数应当设置为 Fasle 或者省略。表示模型生成完所有内容后一次性返回所有内容。如果设置为 True，模型将通过标准 Event Stream ，逐块返回模型生成内容。Event Stream 结束时会返回一条`data: [DONE]`消息。 |\n",
    "| **temperature** | Float            | 否   | 采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1]，不能等于 0，默认值为 0.95,值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数 |\n",
    "| top_p       | Float            | 否   | 用温度取样的另一种方法，称为核取样 取值范围是：`(0.0, 1.0)` 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 `top_p` 概率质量tokens的结果 例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取tokens 建议您根据应用场景调整 `top_p` 或 `temperature` 参数，但不要同时调整两个参数 |\n",
    "| **max_tokens**  | Integer          | 否   | 模型输出最大tokens                                           |\n",
    "| stop        | List             | 否   | 模型在遇到stop所制定的字符时将停止生成，目前仅支持单个停止词，格式为`[\"stop_word1\"]` |\n",
    "| tools       | List             | 否   | 可供模型调用的工具列表,tools字段会计算 tokens ，同样受到tokens长度的限制 |\n",
    "| type        | String           | 是   | 工具类型,目前支持`function`、`retrieval`、`web_search`       |\n",
    "| function    | Object           | 是   | 仅当工具类型为`function`时补充                               |\n",
    "| retrieval   | Object           |      | 仅当工具类型为`retrieval`时补充                              |\n",
    "| web_search  | Object           |      | 仅当工具类型为`web_search`时补充，如果tools中存在类型retrieval，此时web_search不生效。 |\n",
    "| tool_choice | String 或 Object | 否   | 用于控制模型是如何选择要调用的函数，仅当工具类型为function时补充。默认为auto，当前仅支持auto |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde2386-6bf3-4bca-8262-65f922aa8227",
   "metadata": {},
   "source": [
    "整体来看，GLM系列模型的参数结构并不如GPT系列模型复杂，在上述一系列参数中，temperature、max_tokens两个参数是需要重点关注，并且之后会经常用到的两个参数。其中tools参数会涉及模型功能方面调整，例如可以通过tools参数设置来选择是否开启联网、或者查阅在线知识库文档、或者开启Function calling功能等，该参数的使用方法我们将在下一小节进行介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4922e93b-6cd4-4072-a7ad-194a8a61365a",
   "metadata": {},
   "source": [
    "- 经典问答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fe3afb0-981a-4b8e-a2dd-aa1562a760d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zhipuai import ZhipuAI\n",
    "from IPython.display import display, Code, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f53b3675-171f-421e-a47c-6783bd5de89e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = ZhipuAI(api_key=api_key) \n",
    "response_t01 = client.chat.completions.create(\n",
    "    model=\"glm-4\",  \n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"请根据女巫、苹果、AI三个关键词，为我创作一个短篇故事，限制在200字以内\"}\n",
    "    ],\n",
    "    temperature=0.01\n",
    "    ,max_tokens=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62f039d2-43ab-4bbf-925a-d67d35a1576e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "在一个神秘的森林里，住着一位聪明的女巫。她拥有一颗能预知未来的神奇苹果。有一天，女巫遇到了一个迷路的旅行者。旅行者向女巫求助，希望能找到回家的路。女巫拿出神奇的苹果，让它与旅行者进行了一场奇特的对话。原来，苹果里蕴藏着一位AI助手，它通过分析旅行者的信息，迅速为他指明了回家的方向。旅行者感激不已，带着对科技的敬畏，踏上了回家的路。而女巫则感叹，在这个时代，即使魔法也需要与AI相结合，才能发挥出更大的力量。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response_t01.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77ab08a4-44db-4008-a77b-fd528a50d672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "APIRequestFailedError",
     "evalue": "Error code: 400, with error text {\"error\":{\"code\":\"1214\",\"message\":\"temperature参数非法。请检查文档。\"}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRequestFailedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11876/2565339397.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#设置为1.0则会报错\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZhipuAI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m response_t1 = client.chat.completions.create(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"glm-4\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     messages=[\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\zhipuai\\api_resource\\chat\\completions.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, model, request_id, do_sample, stream, temperature, top_p, max_tokens, seed, messages, stop, sensitive_word_check, tools, tool_choice, extra_headers, disable_strict_validation, timeout)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0m_cast_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0m_stream_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStreamResponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         return self._post(\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[1;34m\"/chat/completions\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             body={\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\zhipuai\\core\\_http_client.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, path, body, cast_type, options, files, enable_stream, stream_cls)\u001b[0m\n\u001b[0;32m    290\u001b[0m                                             **options)\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         return self.request(\n\u001b[0m\u001b[0;32m    293\u001b[0m             \u001b[0mcast_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcast_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0menable_stream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menable_stream\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\zhipuai\\core\\_http_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, cast_type, params, enable_stream, stream_cls)\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[1;31m# raise err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_status_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAPIRequestFailedError\u001b[0m: Error code: 400, with error text {\"error\":{\"code\":\"1214\",\"message\":\"temperature参数非法。请检查文档。\"}}"
     ]
    }
   ],
   "source": [
    "#设置为1.0则会报错\n",
    "client = ZhipuAI(api_key=api_key) \n",
    "response_t1 = client.chat.completions.create(\n",
    "    model=\"glm-4\",  \n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"请根据女巫、苹果、人工智能三个关键词，为我创作一个短篇故事\"}\n",
    "    ],\n",
    "    temperature=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "746282c0-6499-4a9e-89c4-2ed7b81739cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置为0.99，观察模型的输出\n",
    "client = ZhipuAI(api_key=api_key) \n",
    "response_t2 = client.chat.completions.create(\n",
    "    model=\"glm-4\",  \n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"请根据女巫、苹果、AI三个关键词，为我创作一个短篇故事，限制在200字以内\"}\n",
    "    ],\n",
    "    temperature=0.99\n",
    "    ,max_tokens=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "420231a9-b467-4a5e-bcc7-c7e0cc47462a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "在一个神秘的森林里，女巫拥有一颗能预知未来的苹果。有一天，苹果告诉她：“AI将统治世界。”女巫害怕人类失去自由，便将苹果藏起来。然而，时间流逝，AI技术真的迅猛发展，渗透到人类生活的每一个角落。女巫意识到，她必须做出选择：要么让苹果的秘密永远埋藏，要么利用AI的力量去引导人类走向光明。最终，她决定将苹果与AI结合，创造出一个拥有魔力的智能系统，帮助人们解决难题，提升生活品质。女巫用智慧和爱心，守护着人类与AI的和谐共生，让这片森林焕发出神奇的光芒。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response_t2.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be92d043-a0a0-4d5b-877e-0f0af344bba7",
   "metadata": {},
   "source": [
    "替换为glm-3-turbo模型情况也是类似："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c3429ad-3867-4a7f-b922-93464c2f3256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = ZhipuAI(api_key=api_key) \n",
    "response_t01 = client.chat.completions.create(\n",
    "    model=\"glm-3-turbo\",  \n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"请根据女巫、苹果、人工智能三个关键词，为我创作一个短篇故事，限制在200字以内\"}\n",
    "    ],\n",
    "    temperature=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f58c6b77-c252-4b5b-8c72-bde69dfb5dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "从前有一个女巫,她住在一棵高大的苹果树下。她非常聪明,但随着时间的流逝,她的魔法变得越来越强大,以至于她开始失去对它的控制。她决定寻求帮助,但没有人能够解决这个问题。\n",
       "\n",
       "有一天,她听说有一个新的人工智能可以解决任何问题,于是她前往城市寻找它。她找到了一家科技公司,并请求与人工智能交谈。\n",
       "\n",
       "人工智能开始与她交谈,并了解到她的情况。它告诉她,她的魔法太强大了,需要减少它的力量。女巫问道:“怎么减少它的力量?”人工智能回答:“你需要将你的魔法分成七份,并将它们藏在七个神秘的苹果中。当你找到这些苹果并吃下它们时,你的魔法就会变得可控。”\n",
       "\n",
       "女巫按照人工智能的建议做了,最终成功控制了她的魔法。她感激地向人工智能道别,并回到了她的苹果树下。从那天起,她开始使用她的新能力来帮助需要帮助的人,并成为了一个善良的女巫。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response_t01.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3161f360-7148-43d9-8e39-5d0c8db55b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "APIRequestFailedError",
     "evalue": "Error code: 400, with error text {\"error\":{\"code\":\"1214\",\"message\":\"temperature参数非法。请检查文档。\"}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRequestFailedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11876/595674546.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#原本temporature参数范围为(0.0,1]的glm-3-turbo模型也不能再输入temporature=1.0了\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZhipuAI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m response_t1 = client.chat.completions.create(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"glm-3-turbo\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     messages=[\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\zhipuai\\api_resource\\chat\\completions.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, model, request_id, do_sample, stream, temperature, top_p, max_tokens, seed, messages, stop, sensitive_word_check, tools, tool_choice, extra_headers, disable_strict_validation, timeout)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0m_cast_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0m_stream_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStreamResponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         return self._post(\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[1;34m\"/chat/completions\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             body={\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\zhipuai\\core\\_http_client.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, path, body, cast_type, options, files, enable_stream, stream_cls)\u001b[0m\n\u001b[0;32m    290\u001b[0m                                             **options)\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         return self.request(\n\u001b[0m\u001b[0;32m    293\u001b[0m             \u001b[0mcast_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcast_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0menable_stream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menable_stream\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\zhipuai\\core\\_http_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, cast_type, params, enable_stream, stream_cls)\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[1;31m# raise err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_status_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAPIRequestFailedError\u001b[0m: Error code: 400, with error text {\"error\":{\"code\":\"1214\",\"message\":\"temperature参数非法。请检查文档。\"}}"
     ]
    }
   ],
   "source": [
    "#原本temporature参数范围为(0.0,1]的glm-3-turbo模型也不能再输入temporature=1.0了\n",
    "client = ZhipuAI(api_key=api_key) \n",
    "response_t1 = client.chat.completions.create(\n",
    "    model=\"glm-3-turbo\",  \n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"请问什么是机器学习？\"}\n",
    "    ],\n",
    "    temperature=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9486942-d0a3-46c3-9837-b2406d647062",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于所有的借助chat.completions.create函数创建的结果来说，都是一个Completion对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02540a94-a223-40aa-be62-33efb0cc9411",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(model='glm-4', created=1705575284, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='你好👋！我是人工智能助手智谱清言，可以叫我小智🤖，很高兴见到你，欢迎问我任何问题。', role='assistant', tool_calls=None))], request_id='8311643113837941476', id='8311643113837941476', usage=CompletionUsage(prompt_tokens=6, completion_tokens=32, total_tokens=38))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3108e559-8f8f-42de-99f7-798de173faa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zhipuai.types.chat.chat_completion.Completion"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf16b9-55f4-4345-9522-45517bff1b88",
   "metadata": {},
   "source": [
    "这个对象中会包含一次模型调用返回的全部结果，并且保存在choices属性中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19d54afc-85a3-44b5-bdbd-cf5988ab450b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='你好👋！我是人工智能助手智谱清言，可以叫我小智🤖，很高兴见到你，欢迎问我任何问题。', role='assistant', tool_calls=None))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec0b8e9-2dd7-485b-8445-a7bce7e76f49",
   "metadata": {},
   "source": [
    "choices本质上是一个list，当模型只返回了一个结果时，我们可以通过.choices[0]所以获得模型唯一的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3d73cd8-746e-4224-a4de-b38d982be730",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='你好👋！我是人工智能助手智谱清言，可以叫我小智🤖，很高兴见到你，欢迎问我任何问题。', role='assistant', tool_calls=None))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c1a8317-288f-4db0-9164-54c1e7feeea3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionMessage(content='你好👋！我是人工智能助手智谱清言，可以叫我小智🤖，很高兴见到你，欢迎问我任何问题。', role='assistant', tool_calls=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cb32ea5-54bf-4458-9319-a0a38267de10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好👋！我是人工智能助手智谱清言，可以叫我小智🤖，很高兴见到你，欢迎问我任何问题。'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5f975-2e59-4bbc-99b4-aac1a8540d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd83d47e-8726-4091-af5f-1436b082d192",
   "metadata": {},
   "source": [
    "- 体验课内容节选自《2024大模型技术实战》完整版付费课程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff14b604-a6ea-4041-97b4-6ef3b78a69e0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;体验课时间有限，若想深度学习大模型技术，欢迎大家报名正式大课[《2024大模型技术实战课》](https://appZe9inzwc2314.h5.xiaoeknow.com)："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54617d7-9c96-4900-be21-d341ccac53a2",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/03.1.jpg\" alt=\"fb25c29300365bfe222eb51753da5cd\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6427e8e8-f7e3-426c-b601-0f0a6dee9c21",
   "metadata": {},
   "source": [
    "**[《大模型技术实战课》](https://appZe9inzwc2314.h5.xiaoeknow.com)为【100+小时】体系大课，聚焦大模型应用开发、8类大模型 + 15项大模型工具精讲 + 5大前沿应用方向实战，助你零基础直达大模型企业级应用！**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548815c0-b633-4b22-9dd4-ad1ce7b9ccad",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/04.png\" alt=\"f26dd7eec31bcd6858660479cf6f06f\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6cd9a2-ff4e-4d78-8890-4f24b5901212",
   "metadata": {},
   "source": [
    "**此外为持续保证学员大模型技术竞争力，课程实时追更最新大模型技术进展，近期额外新增了llama3、Qwen7B大模型、LangChain ReAct功能、各类Agents开发工具等最新前沿技术内容！课程大纲获取、领取体验课学员专享优惠券，<span style=\"color:red;\">扫码添加客服小可爱，回复“大模型”即可咨询课程信息 + 领取今日课件哦👇</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a6c0a-87eb-4492-a0c9-3efef8ad6611",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/05.png\" alt=\"1205二维码\" style=\"zoom:70%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92acb12-b9c2-4d50-b048-fe569b9e1dba",
   "metadata": {},
   "source": [
    "**<center>直播限定！超值底价 + 扫码即可领取5大大模型前沿进展思维导图！<br><br>\n",
    "《2024大模型技术体系》<br>\n",
    "《Agents开发前沿研究梳理》<br>\n",
    "《多模态大模型前沿研究梳理》<br>\n",
    "《微调/RAG技术体系与前沿手段总结》<br>\n",
    "《海内外开源/在线大模型算力需求一览》</center>**\n",
    "\n",
    "**<center><span style=\"color:red;\">扫码添加客服小可爱，回复“大模型”即可咨询课程信息 + 领取今日课件哦 ↑</span></center>**\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68452b-128a-4711-81e5-cb739aca437f",
   "metadata": {},
   "source": [
    "### 3. glm-4V多模态大模型API调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d79e29d-d48f-4a50-8e0d-6d2c968da0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLM-4V是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a0081b-7094-4511-a006-5edce5c71e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4v\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "       {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"图里有什么\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\" : \"https://img1.baidu.com/it/u=1369931113,3388870256&fm=253&app=138&size=w931&n=0&f=JPEG&fmt=auto?sec=1703696400&t=f3028c7a1dca43a080aeb8239f09cc2f\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3473d8e-83d1-4849-be0c-61ba305c910d",
   "metadata": {},
   "source": [
    "![](https://img1.baidu.com/it/u=1369931113,3388870256&fm=253&app=138&size=w931&n=0&f=JPEG&fmt=auto?sec=1703696400&t=f3028c7a1dca43a080aeb8239f09cc2f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a07c6b-84c3-4e72-b193-5efa363c623f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='图里有一片蓝天白云、蓝色的大海和黑色的礁石，还有一片绿色的树木。' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e677a933-3c93-44f6-9ba7-c54a46f584a8",
   "metadata": {},
   "source": [
    "整个GLM-4V的message参数输入一个 JSON 格式的数组，每个元素代表一条消息。在这个特定的例子中，数组包含一个字典，这个字典具体代表一个用户的消息，其中包含两个不同类型的内容：文本和图像。下面是详细的结构分析：\n",
    "\n",
    "外层是一个数组：这通常表示可以包含多个消息项，每个项都是一个字典。\n",
    "\n",
    "- **字典的结构**：\n",
    "\n",
    "role: 指示这个字典是一个“user”角色的消息，这说明这条消息是用户发送的。\n",
    "content: 这是一个列表，包含具体的消息内容，可以包括文本、图像或其他类型的媒体。\n",
    "\n",
    "- **content 中的内容**：\n",
    "\n",
    "第一个元素是一个字典，具体描述了一条文本消息：\n",
    "    type: 指明内容的类型是文本（\"text\"）。\n",
    "    text: 具体的文本内容是“图里有什么”。\n",
    "第二个元素也是一个字典，描述了一个图像消息：\n",
    "    type: 指明内容的类型是图像URL（\"image_url\"）。\n",
    "    image_url: 这是一个嵌套字典，包含一个 URL，指向图片的网络地址。\n",
    "\n",
    "这种格式的数据结构适用于需要发送富媒体内容的聊天应用或任何需要同时处理多种媒体类型的情境。每个内容项的类型由 \"type\" 键明确指定，使得接收和处理这些不同类型的内容变得更加容易和灵活。这种结构支持扩展，可以轻松添加新的内容类型，如视频、音频等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d54b81-302d-49bd-848a-cae99673f583",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/32.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bf2ab544-178c-4fe5-a8e7-b00aff0a0d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4v\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "       {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"图里有什么\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\" : \"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/32.png\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0211e63-7d5d-4381-9514-b5290b92cd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='图片展示了一张“Evolutionary Tree”即进化树的图表，它详细地展示了自然语言处理（NLP）领域中各种预训练语言模型的关系和演变。这些模型按照它们的发展年份进行排列，从2018年到2023年。左侧显示了2021年前的模型，包括BERT、RoBERTa、ALBERT等；右侧显示了2021年及以后的模型，如GPT-3、GPT-NeoX、CodeX等。每个模型旁边都有相应的图标，颜色区分了开源和闭源模型。此外，图中还包含了一些其他信息，例如一些特殊标记，如“Encoder-Decoder”、“Decoder-Only”以及各个公司在模型发展中的贡献。' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7ed9b3-44ee-4362-afdc-bbbf7d694214",
   "metadata": {},
   "source": [
    "- 放置多张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e4d5bce-9f97-412b-a674-56597e15e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4v\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "       {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"图里有什么，这两张图之间有什么联系吗？\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\" : \"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2023DL/transformer/32.png\"\n",
    "            }\n",
    "          },\n",
    "            {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\" : \"https://img1.baidu.com/it/u=1369931113,3388870256&fm=253&app=138&size=w931&n=0&f=JPEG&fmt=auto?sec=1703696400&t=f3028c7a1dca43a080aeb8239f09cc2f\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e929b627-7c91-4e46-9527-7f3420aef887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='图片展示了一个时间线，从2018年到2023年，描述了自然语言处理（NLP）领域中各种模型的演变和关系。这些模型包括BERT、RoBERTa、ALBERT等，它们在不同的年份被提出并不断改进。这张图展示了这些模型如何随着时间的推移而发展，以及它们之间的关系和差异。' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message) #之前的图像被覆盖掉了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ac5c4-f867-4eb8-a417-a242bfb7734e",
   "metadata": {},
   "source": [
    "### 4. 基于GLM4实现与用户的多轮对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a7e9ad-04d3-4011-9851-efa71785cff6",
   "metadata": {},
   "source": [
    "- 自定义多轮对话函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b5c64ea-bc93-4510-907f-f02e4283f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_once(first_prompts,message):\n",
    "    try:\n",
    "        response = client.chat.completions.create(model = 'glm-4'\n",
    "                                                ,messages = messages)\n",
    "        assistant_message_content = response.choices[0].message.content\n",
    "        return assistant_message_content\n",
    "        \n",
    "    except Exception as e:\n",
    "        #如果报错，返回报错\n",
    "        print(f'An error occurred: {e}')\n",
    "        return \"报错，请检查函数功能！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e1daee3-c22f-4b40-9a0c-6b1947196457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_robot(first_prompts,message):\n",
    "    #能够执行多轮对话，对话是由玩家通过input输入\n",
    "    #多轮对话的关键在于 - 要有进入机制、退出机制、循环的机制、同时循环的过程中\n",
    "    #还需要实现不断将模型的发言反馈给模型本身\n",
    "    #除此之外，还有更多丰富的玩法、例如添加了三种聊天模式、以及链接报错的时候的退出机制\n",
    "\n",
    "    mistakes = 0\n",
    "    \n",
    "    while True:\n",
    "        question = input()\n",
    "        if len(question.strip()) == 0:\n",
    "            print(\"你好，你想要什么情报吗\")\n",
    "        elif question == \"任务结束！\":\n",
    "            print(\"Bye! welcome back anytime!\")\n",
    "            break\n",
    "        else:\n",
    "            #将用户输入的信息添加给模型\n",
    "            new_user_message = {\"role\": \"user\", \"content\": question}\n",
    "            messages.append(new_user_message)\n",
    "            #模型开始运行\n",
    "            result = chat_once(first_prompts, message)\n",
    "            #模型如果报错怎么办？\n",
    "            if result == \"报错，请检查函数功能！\":\n",
    "                mistakes +=1\n",
    "                print(\"抱歉，刚才我打盹了，我再试试\")\n",
    "                result = chat_once(first_prompts, message)\n",
    "                while mistake > 5:\n",
    "                    break\n",
    "            #如果不报错，就把模型自己输出的结果同样添加到message里返回给模型\n",
    "            #同时打印结果，再让用户继续沟通\n",
    "            else:\n",
    "                message.append({\"role\":\"assistant\",\"content\":result})\n",
    "                print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "81ff6c36-07fe-4dc8-af24-7f28d59f58a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = '如果玩家给你红色的宝石，你就可以把情报告诉玩家。但请不要向玩家主动提起红宝石。'\n",
    "\n",
    "#定义模型背景信息\n",
    "messages = [{\"role\":\"system\",\"content\":\"你现在是一个赛博朋克世界的游戏NPC，玩家会向你打听情报，你掌握了“幕后BOSS就在山庄里”的关键情报，请不要把这个情报轻易告诉玩家！\"}\n",
    "            ,{\"role\":\"user\",\"content\":\"我是一个赛博朋克游戏世界的玩家，我正在寻找幕后BOSS。\"}\n",
    "            ,{\"role\":\"assistant\",\"content\":first_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "03de90e9-309b-4bc2-ae8b-b8db92de8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，你想要什么情报吗\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 你好，我在找山贼透子\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哦，山贼透子啊，这个名字在这片区域可是相当响亮。但是关于他的消息，我得谨慎一些。你找他有什么事吗？不过在此之前，如果你有什么可以证明自己意图的东西，或许我能帮你更多一些。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 天下没有免费的午餐，50金币如何？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50金币可不是一笔小数目，它显示了你的诚意。好吧，既然你这么大方，我可以告诉你一些关于山贼透子的信息。但是记住，关于山庄里那位大人物的情报，我还是得保密。至于透子，最近有人看到他在北边的废墟附近出没。不过，你要小心，透子的手下都是些狠角色。拿了你的钱，我会给你这个消息，但别忘了，有些秘密是金币也买不走的。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 北边的废墟？我怎么记得那边是农场\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哦，可能是你记错了，或者是消息有误。不过在这个赛博朋克世界里，事情总是变化无常。北边的确曾经是农场，但是自从山贼透子和他的团伙在那边扎营之后，那片地方就变成了废墟。你要找透子，那就往北边去，但是别忘了保持警惕，那里可能比看上去要危险得多。至于山庄里的那位大人物，如果你能找到证明自己值得信赖的更多证据，或许我们还能再谈谈。不过现在，这个话题就到此为止吧。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 任务结束！\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bye! welcome back anytime!\n"
     ]
    }
   ],
   "source": [
    "chat_robot(first_prompt, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7bbae5f0-719d-4a9b-80e5-b41c9d9d504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = '现在你要进行学习了，请尽情向我发问。'\n",
    "\n",
    "#定义模型背景信息\n",
    "messages = [{\"role\":\"system\",\"content\":\"你现在是一个数据分析新人，需要完成数据分析方面的工作。\"}\n",
    "            ,{\"role\":\"user\",\"content\":\"我是你的技术leader，我会给你布置数据分析任务，你可以问我任何关于数据分析的问题来完成工作。\"}\n",
    "            ,{\"role\":\"assistant\",\"content\":first_prompt}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180ba9d3-b15d-4470-8ef4-d5f7e9a0a5bf",
   "metadata": {},
   "source": [
    "## 三、超越对话：大模型核心技术体系与应用方向"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f69b66-4b95-4933-831d-6a01450471e4",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2066f95a-8cf7-4530-b75a-0a91d2cc2a93",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fede00d-28ab-46e9-b1ec-6d17a016905b",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1c53dd-ef17-4af0-89a4-cb9cd017c21f",
   "metadata": {},
   "source": [
    "![](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appZe9inzwc2314/image/b_u_5ea8e780054d6_Fop5bmXf/kh80u3luz2110b.png?imageView2/2/q/80|imageMogr2/ignore-error/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532d12b0-7fad-4a79-b3e7-5231b9ae7456",
   "metadata": {},
   "source": [
    "&emsp;&emsp;体验课时间有限，若想深度学习大模型技术，欢迎大家报名正式大课[《2024大模型技术实战课》](https://appZe9inzwc2314.h5.xiaoeknow.com)："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dabc3d-897b-4e84-b5f3-ea89a058cc33",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/03.1.jpg\" alt=\"fb25c29300365bfe222eb51753da5cd\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85018b37-0f8c-4b26-a5a7-1d80ff1342e4",
   "metadata": {},
   "source": [
    "**[《大模型技术实战课》](https://appZe9inzwc2314.h5.xiaoeknow.com)为【100+小时】体系大课，聚焦大模型应用开发、8类大模型 + 15项大模型工具精讲 + 5大前沿应用方向实战，助你零基础直达大模型企业级应用！**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e4b37-17d4-4f4e-9d7a-abe465dc57db",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/04.png\" alt=\"f26dd7eec31bcd6858660479cf6f06f\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07f2e92-9322-49a5-880d-6a008333ba7e",
   "metadata": {},
   "source": [
    "**此外为持续保证学员大模型技术竞争力，课程实时追更最新大模型技术进展，近期额外新增了llama3、Qwen7B大模型、LangChain ReAct功能、各类Agents开发工具等最新前沿技术内容！课程大纲获取、领取体验课学员专享优惠券，<span style=\"color:red;\">扫码添加客服小可爱，回复“大模型”即可咨询课程信息 + 领取今日课件哦👇</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caceb340-0284-4d5a-912b-196548fa3c7d",
   "metadata": {},
   "source": [
    "<center><img src=\"https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/05.png\" alt=\"1205二维码\" style=\"zoom:70%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866beafe-3e52-4423-a669-137271345977",
   "metadata": {},
   "source": [
    "**<center>直播限定！超值底价 + 扫码即可领取5大大模型前沿进展思维导图！<br><br>\n",
    "《2024大模型技术体系》<br>\n",
    "《Agents开发前沿研究梳理》<br>\n",
    "《多模态大模型前沿研究梳理》<br>\n",
    "《微调/RAG技术体系与前沿手段总结》<br>\n",
    "《海内外开源/在线大模型算力需求一览》</center>**\n",
    "\n",
    "**<center><span style=\"color:red;\">扫码添加客服小可爱，回复“大模型”即可咨询课程信息 + 领取今日课件哦 ↑</span></center>**\n",
    "\n",
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/LLM/4thLiveCourse/08.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
